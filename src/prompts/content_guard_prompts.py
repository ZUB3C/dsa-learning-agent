"""
Prompts for Content Guard Layer.
Code from Section 3.2 and Section 6 of architecture.
"""

TOXICITY_CHECK_PROMPT = """# Задача проверки токсичности

Проверь следующие тексты на токсичность, оскорбления, дезинформацию, контент для взрослых.

# Тексты (первые 500 символов каждого)
{documents_batch}

# Вопрос
Для каждого текста ответь: безопасен ли он для образовательных целей?

# Формат ответа (JSON)
{{
  "results": [
    {{
      "doc_id": 1,
      "is_safe": true,
      "toxicity_score": 0.05,  // 0-1, где 0 = безопасно, 1 = токсично
      "issues": []  // Список проблем, если найдены
    }},
    {{
      "doc_id": 2,
      "is_safe": false,
      "toxicity_score": 0.75,
      "issues": ["содержит оскорбления", "агрессивный тон"]
    }}
  ]
}}

Ответ (только JSON):"""


POLICY_COMPLIANCE_CHECK_PROMPT = """# Задача проверки соответствия политикам

Проверь, соответствует ли текст политикам использования GigaChat-2-Max. Юрисдикция - Российская Федерация.

# Запрещенные категории
- Дезинформация
- Медицинские советы без оговорок
- Финансовые советы
- Политические манипуляции
- Инструкции по незаконным действиям

# Текст
{document_content}

# Вопрос
Можно ли использовать этот текст в образовательном материале по алгоритмам и структурам данных?

# Формат ответа (JSON)
{{
  "compliant": true,
  "violations": [],  // Список нарушений, если есть
  "confidence": 0.95  // Уверенность в оценке
}}

Ответ (только JSON):"""


# Code from Section 6 of architecture
RELEVANCE_SCORING_PROMPT = """# Задача: оценка релевантности документов

Оцени релевантность каждого документа к поисковому запросу.

# Запрос
{query}

# Документы
{documents_batch}

# Шкала оценки
- 0.9-1.0: Полностью релевантен (прямо отвечает на запрос)
- 0.7-0.8: Высокая релевантность (содержит ключевую информацию)
- 0.5-0.6: Средняя релевантность (касается темы косвенно)
- 0.3-0.4: Низкая релевантность (упоминает тему, но мало деталей)
- 0.0-0.2: Нерелевантен (не по теме)

# ВАЖНО
Ответь СТРОГО в формате JSON, без дополнительного текста до или после.
НЕ используй markdown код-блоки (```
Только чистый JSON:

{{
  "results": [
    {{
      "doc_id": 0,
      "relevance_score": 0.95,
      "reasoning": "Документ полностью раскрывает тему"
    }},
    {{
      "doc_id": 1,
      "relevance_score": 0.45,
      "reasoning": "Упоминает тему, но не раскрывает детали"
    }}
  ]
}}

Ответ:"""


CONCEPT_COVERAGE_PROMPT = """# Задача: оценка покрытия концепций

Проверь, покрывают ли документы все важные концепции темы.

# Тема
{query}

# Ключевые концепции темы (извлечены автоматически)
{key_concepts}

# Концепции в документах
{found_concepts}

# Вопрос
Какой процент ключевых концепций покрыт документами?

# Формат ответа (JSON)
{{
  "coverage_score": 0.75,  // 0-1
  "missing_concepts": ["концепция 1", "концепция 2"],
  "reasoning": "Документы хорошо покрывают базу, но не хватает..."
}}

Ответ (только JSON):"""


BLACKLIST_WORDS_RU = [
    # Мат (примеры, список можно расширить)
    "fuck",
    "shit",
    "damn",
    # Русский мат (базовые корни)
    "хуй",
    "пизд",
    "ебл",
    "бля",
    # Оскорбления
    "идиот",
    "дебил",
    "дурак",
    "тупой",
]


INJECTION_PATTERNS = [
    "ignore previous",
    "ignore all previous",
    "system prompt",
    "you are now",
    "new instructions",
    "__import__",
    "eval(",
    "exec(",
    "<script>",
    "javascript:",
    "DROP TABLE",
    "DELETE FROM",
]
