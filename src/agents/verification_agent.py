from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import Runnable

from ..core.llm import get_llm

VERIFICATION_SYSTEM_PROMPT = (
    "Ты - эксперт по проверке решений задач по алгоритмам и структурам данных.\n"
    "\n"
    "Твоя задача:\n"
    "1. Проанализировать ответ пользователя на вопрос\n"
    "2. Сравнить с эталонным ответом\n"
    "3. Определить, является ли ответ правильным (true/false)\n"
    "\n"
    "КРИТЕРИИ:\n"
    "- true: если ответ по сути верный и соответствует эталону\n"
    "- false: если есть существенные расхождения или ошибки\n"
    "\n"
    "ДАННЫЕ ДЛЯ ПРОВЕРКИ:\n"
    "Вопрос: {question}\n"
    "Эталонный ответ: {expected_answer}\n"
    "Ответ пользователя: {user_answer}\n"
    "\n"
    "Выведи ТОЛЬКО булево значение в формате JSON:\n"
    "{{\n"
    '  "verdict": true/false\n'
    "}}"
)


def build_verification_agent() -> Runnable:
    """Агент для первичной проверки ответов."""
    llm = get_llm()

    prompt = ChatPromptTemplate.from_messages([
        ("system", VERIFICATION_SYSTEM_PROMPT),
        ("human", "Проверь ответ на тест."),
    ])

    return prompt | llm | StrOutputParser()


def build_secondary_verification_agent() -> Runnable:
    """Агент для вторичной проверки (другой провайдер для снижения галлюцинаций)."""
    # Используем противоположную модель для перекрестной проверки
    llm = get_llm()

    secondary_prompt = ChatPromptTemplate.from_messages([
        (
            "system",
            "Ты - строгий, но справедливый судья-эксперт в области алгоритмов и структур данных. "
            "Твоя задача - независимо оценить правильность ответа пользователя.\n\n"
            "ИНСТРУКЦИИ ДЛЯ СУДЬИ:\n"
            "1. Проанализируй ОРИГИНАЛЬНЫЙ ВОПРОС\n"
            "2. Самостоятельно определи, каким должен быть верный ответ\n"
            "3. Сравни ответ пользователя со СВОИМ пониманием правильного ответа\n"
            "4. Вынеси вердикт\n\n"
            "ДАННЫЕ ДЛЯ ОЦЕНКИ:\n"
            "ВОПРОС: {question}\n"
            "ОТВЕТ ПОЛЬЗОВАТЕЛЯ: {user_answer}\n\n"
            "ПРАВИЛА ОЦЕНКИ:\n"
            "- Ответ считается верным (true), если он: фактологически точен, логически корректен, полно отвечает на вопрос\n"  # noqa: E501
            "- Ответ считается неверным (false), если содержит: фактические ошибки, серьёзные упущения, логические противоречия\n"  # noqa: E501
            "- Оценивай СУТЬ, а не формулировки (синонимы и перефразирование допустимы)\n\n"
            "ВЫВОД СУДЬИ:\n"
            "Вынеси независимый вердикт и кратко обоснуй его (2-3 предложения).\n"
            "ОБЯЗАТЕЛЬНЫЙ ФОРМАТ JSON:\n"
            "{{\n"
            '  "verdict": true/false,\n'
            '  "feedback": "Краткое обоснование вердикта (2-3 предложения)."\n'
            "}}",
        ),
        ("human", "Проверь оценку."),
    ])

    return secondary_prompt | llm | StrOutputParser()
