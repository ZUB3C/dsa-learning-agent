import argparse
import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Any

from pydantic import BaseModel

from src.agents.registry import load_agent

# =======================
# Models
# =======================


class Question(BaseModel):
    question_id: int
    difficulty: str
    question_text: str
    expected_answer: str
    user_answer: str
    key_points: list[str]
    is_correct: bool


class Topic(BaseModel):
    topic_id: str
    topic_name: str
    questions: list[Question]


class TestCollection(BaseModel):
    creation_date: str
    total_questions: int
    topics_count: int
    topics: list[Topic]


class PrimaryEvaluation(BaseModel):
    verdict: bool


class SecondaryEvaluation(BaseModel):
    verdict: bool
    agree_with_primary: bool
    feedback: str


class TestVerification(BaseModel):
    question_id: int
    topic: str
    difficulty: str
    question_text: str
    user_answer: str
    expected_answer: str
    ground_truth: bool
    primary_evaluation: PrimaryEvaluation
    secondary_evaluation: SecondaryEvaluation
    timestamp: str


class VerificationMetrics(BaseModel):
    total_verifications: int
    agreement_count: int
    disagreement_count: int
    agreement_rate: float
    primary_accuracy: float
    secondary_accuracy: float
    improvement_rate: float
    true_positive: int
    true_negative: int
    false_positive: int
    false_negative: int
    false_positive_rate: float


class EffectivenessReport(BaseModel):
    report_date: str
    overall_metrics: VerificationMetrics
    verifications: list[TestVerification]


# =======================
# Verification logic
# =======================


async def verify_answer(
    question: Question,
) -> tuple[PrimaryEvaluation, SecondaryEvaluation]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å –ø–æ–º–æ—â—å—é –ø–µ—Ä–≤–∏—á–Ω–æ–π –∏ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏."""
    primary_agent = load_agent("verification")
    primary_raw = await primary_agent.ainvoke({
        "question": question.question_text,
        "expected_answer": question.expected_answer,
        "user_answer": question.user_answer,
    })

    try:
        primary_eval = PrimaryEvaluation(**json.loads(primary_raw))
    except Exception:
        primary_eval = PrimaryEvaluation(verdict=False)

    secondary_agent = load_agent("verification-secondary")
    secondary_raw = await secondary_agent.ainvoke({
        "primary_verdict": primary_eval.verdict,
        "question": question.question_text,
        "user_answer": question.user_answer,
        "expected_answer": question.expected_answer,
    })

    try:
        secondary_eval = SecondaryEvaluation(**json.loads(secondary_raw))
    except Exception:
        secondary_eval = SecondaryEvaluation(
            verdict=primary_eval.verdict,
            agree_with_primary=True,
            feedback="–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ —Å—É–¥—å–∏",
        )

    return primary_eval, secondary_eval


async def process_verifications(
    test_collection: TestCollection,
) -> list[TestVerification]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã –∏ —Å–æ–∑–¥–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–π."""
    results: list[TestVerification] = []

    for topic in test_collection.topics:
        for question in topic.questions:
            primary, secondary = await verify_answer(question)
            results.append(
                TestVerification(
                    question_id=question.question_id,
                    topic=topic.topic_name,
                    difficulty=question.difficulty,
                    question_text=question.question_text,
                    user_answer=question.user_answer,
                    expected_answer=question.expected_answer,
                    ground_truth=question.is_correct,
                    primary_evaluation=primary,
                    secondary_evaluation=secondary,
                    timestamp=datetime.now().isoformat(),
                )
            )

    return results


# =======================
# Metrics
# =======================


def calculate_metrics(
    verifications: list[TestVerification],
) -> VerificationMetrics:
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏."""
    total = len(verifications)
    agreement_count = sum(v.secondary_evaluation.agree_with_primary for v in verifications)
    disagreement_count = total - agreement_count

    primary_correct = sum(v.primary_evaluation.verdict == v.ground_truth for v in verifications)
    secondary_correct = sum(
        v.secondary_evaluation.verdict == v.ground_truth for v in verifications
    )

    tp = sum(v.ground_truth and v.secondary_evaluation.verdict for v in verifications)
    tn = sum(not v.ground_truth and not v.secondary_evaluation.verdict for v in verifications)
    fp = sum(not v.ground_truth and v.secondary_evaluation.verdict for v in verifications)
    fn = sum(v.ground_truth and not v.secondary_evaluation.verdict for v in verifications)

    return VerificationMetrics(
        total_verifications=total,
        agreement_count=agreement_count,
        disagreement_count=disagreement_count,
        agreement_rate=agreement_count / total * 100,
        primary_accuracy=primary_correct / total * 100,
        secondary_accuracy=secondary_correct / total * 100,
        improvement_rate=(secondary_correct - primary_correct) / total * 100,
        true_positive=tp,
        true_negative=tn,
        false_positive=fp,
        false_negative=fn,
        false_positive_rate=(fp / (fp + tn) * 100) if (fp + tn) else 0.0,
    )


# =======================
# Report
# =======================


def generate_markdown_report(report: EffectivenessReport) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç markdown –æ—Ç—á–µ—Ç –æ–± —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏."""
    m = report.overall_metrics
    md_lines: list[str] = []

    # ===== –ó–∞–≥–æ–ª–æ–≤–æ–∫ =====
    md_lines.append("# –û—Ç—á—ë—Ç –æ–± —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏\n")
    md_lines.append(f"–î–∞—Ç–∞: {report.report_date}\n")

    # ===== –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ =====
    md_lines.append("## –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n")
    md_lines.append(f"- **–í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–æ–∫:** {m.total_verifications}")
    md_lines.append(f"- **–°–æ–≥–ª–∞—Å–∏–µ –ø—Ä–æ–≤–µ—Ä–æ–∫:** {m.agreement_count} ({m.agreement_rate:.1f}%)")
    md_lines.append(f"- **–†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è:** {m.disagreement_count} ({100 - m.agreement_rate:.1f}%)\n")

    # ===== –ú–µ—Ç—Ä–∏–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ =====
    md_lines.append("### üéØ –¢–æ—á–Ω–æ—Å—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —ç—Ç–∞–ª–æ–Ω–∞\n")
    md_lines.append(f"- **–¢–æ—á–Ω–æ—Å—Ç—å –ø–µ—Ä–≤–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏:** {m.primary_accuracy:.1f}%")
    md_lines.append(f"- **–¢–æ—á–Ω–æ—Å—Ç—å –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ (Judge):** {m.secondary_accuracy:.1f}%")
    md_lines.append(f"- **–£–ª—É—á—à–µ–Ω–∏–µ –æ—Ç –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏:** **{m.improvement_rate:+.1f}%**\n")

    # ===== Confusion Matrix =====
    md_lines.append("### üßÆ Confusion Matrix (Judge)\n")
    md_lines.append(f"- **True Positive (TP):** {m.true_positive}")
    md_lines.append(f"- **True Negative (TN):** {m.true_negative}")
    md_lines.append(f"- **False Positive (FP):** {m.false_positive}")
    md_lines.append(f"- **False Negative (FN):** {m.false_negative}")
    md_lines.append(f"- **False Positive Rate:** {m.false_positive_rate:.1f}%\n")

    # ===== –í—ã–≤–æ–¥—ã =====
    if m.improvement_rate >= 10:
        effectiveness = (
            "‚úÖ **–í—ã—Å–æ–∫–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å**: "
            "–í—Ç–æ—Ä–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤—ã—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏."
        )
    elif m.improvement_rate >= 5:
        effectiveness = (
            "‚úÖ **–£–º–µ—Ä–µ–Ω–Ω–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å**: –í—Ç–æ—Ä–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —É–ª—É—á—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏."
        )
    elif m.improvement_rate > 0:
        effectiveness = "‚ö†Ô∏è **–ù–∏–∑–∫–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å**: –í—Ç–æ—Ä–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–µ—Ç –Ω–µ–±–æ–ª—å—à–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ."
    else:
        effectiveness = "‚ùå **–ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ**: –í—Ç–æ—Ä–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ —É–ª—É—á—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å."

    md_lines.append("## –í—ã–≤–æ–¥—ã –æ–± —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏\n")
    md_lines.append(f"{effectiveness}\n")

    # ===== –¢–ê–ë–õ–ò–¶–ê –ü–û –¢–ï–°–¢-–ö–ï–ô–°–ê–ú =====
    md_lines.append("## –ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º\n")
    md_lines.append(
        "| ID | –¢–æ–ø–∏–∫ | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –≠—Ç–∞–ª–æ–Ω | –ü–µ—Ä–≤–∏—á–Ω–∞—è | –í—Ç–æ—Ä–∏—á–Ω–∞—è | –°–æ–≥–ª–∞—Å–∏–µ | –°—Ç–∞—Ç—É—Å |"
    )
    md_lines.append(
        "|:--:|:------|:---------:|:------:|:---------:|:---------:|:--------:|:------:|"
    )

    for v in report.verifications:
        gt = "‚úì" if v.ground_truth else "‚úó"
        p = "‚úì" if v.primary_evaluation.verdict else "‚úó"
        j = "‚úì" if v.secondary_evaluation.verdict else "‚úó"
        agree = "‚úì" if v.secondary_evaluation.agree_with_primary else "‚úó"

        # –°—Ç–∞—Ç—É—Å
        if v.secondary_evaluation.verdict == v.ground_truth:
            if v.primary_evaluation.verdict == v.ground_truth:
                status = "üü¢"
            else:
                status = "üü°"
        elif v.primary_evaluation.verdict == v.ground_truth:
            status = "üî¥"
        else:
            status = "‚ö´Ô∏è"

        md_lines.append(
            f"| {v.question_id} | {v.topic} | {v.difficulty} | "
            f"{gt} | {p} | {j} | {agree} | {status} |"
        )

    # ===== –õ–µ–≥–µ–Ω–¥–∞ =====
    md_lines.append("\n### –õ–µ–≥–µ–Ω–¥–∞\n")
    md_lines.append(
        "- **–≠—Ç–∞–ª–æ–Ω**: –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ —Å–æ–≥–ª–∞—Å–Ω–æ —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º "
        "(‚úì = –ø—Ä–∞–≤–∏–ª—å–Ω–æ, ‚úó = –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ)."
    )
    md_lines.append(
        "- **–ü–µ—Ä–≤–∏—á–Ω–∞—è/–í—Ç–æ—Ä–∏—á–Ω–∞—è**: –æ—Ü–µ–Ω–∫–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (‚úì = –ø—Ä–∞–≤–∏–ª—å–Ω–æ, ‚úó = –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ)."
    )
    md_lines.append("- **–°–æ–≥–ª–∞—Å–∏–µ**: —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ –ø–µ—Ä–≤–∏—á–Ω–æ–π –∏ –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏.")
    md_lines.append("- **–°—Ç–∞—Ç—É—Å**: —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏:")
    md_lines.append("  - üü¢ **–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ**: –í—Ç–æ—Ä–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É.")
    md_lines.append("  - üü° **–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ**: –í—Ç–æ—Ä–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø—Ä–∞–≤–∏–ª–∞ –æ—à–∏–±–∫—É –ø–µ—Ä–≤–∏—á–Ω–æ–π.")
    md_lines.append(
        "  - üî¥ **–û—à–∏–±–∫–∞**: –í—Ç–æ—Ä–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –∏—Å–ø—Ä–∞–≤–∏–ª–∞ –æ—à–∏–±–∫—É –ø–µ—Ä–≤–∏—á–Ω–æ–π –∏–ª–∏ —Å–æ–∑–¥–∞–ª–∞ –Ω–æ–≤—É—é."
    )
    md_lines.append("  - ‚ö´Ô∏è **–û–±–∞ –Ω–µ–≤–µ—Ä–Ω—ã**: –û–±–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É.\n")

    # ===== –î–ï–¢–ê–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –ü–û –ö–ê–ñ–î–û–ú–£ –í–û–ü–†–û–°–£ =====
    md_lines.append("## üìù –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º\n")

    for v in report.verifications:
        gt_emoji = "‚úÖ" if v.ground_truth else "‚ùå"
        p_emoji = "‚úÖ" if v.primary_evaluation.verdict else "‚ùå"
        j_emoji = "‚úÖ" if v.secondary_evaluation.verdict else "‚ùå"

        md_lines.append(f"### –í–æ–ø—Ä–æ—Å {v.question_id}: {v.topic} ({v.difficulty})\n")
        md_lines.append(f"**–í–æ–ø—Ä–æ—Å:** {v.question_text}\n")
        md_lines.append(f"**–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:** {v.user_answer}\n")
        md_lines.append(f"**–û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç:** {v.expected_answer}\n")
        md_lines.append("**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏:**")
        md_lines.append(
            f"- –≠—Ç–∞–ª–æ–Ω (Ground Truth): {gt_emoji} "
            f"{'–ü—Ä–∞–≤–∏–ª—å–Ω–æ' if v.ground_truth else '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ'}"
        )
        md_lines.append(
            f"- –ü–µ—Ä–≤–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: {p_emoji} "
            f"{'–ü—Ä–∞–≤–∏–ª—å–Ω–æ' if v.primary_evaluation.verdict else '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ'}"
        )
        md_lines.append(
            f"- –í—Ç–æ—Ä–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (Judge): {j_emoji} "
            f"{'–ü—Ä–∞–≤–∏–ª—å–Ω–æ' if v.secondary_evaluation.verdict else '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ'}"
        )
        md_lines.append(
            f"- –°–æ–≥–ª–∞—Å–∏–µ: {'‚úì –î–∞' if v.secondary_evaluation.agree_with_primary else '‚úó –ù–µ—Ç'}"
        )

        if v.secondary_evaluation.feedback:
            md_lines.append(f"\n**–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—É–¥—å–∏:** {v.secondary_evaluation.feedback}")

        md_lines.append("\n---\n")

    return "\n".join(md_lines)


# =======================
# Entrypoint
# =======================


def main(args: argparse.Namespace) -> None:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞."""
    data: dict[str, Any] = json.loads(Path(args.test_data).read_text(encoding="utf-8"))

    # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JSON
    test_collection_data = data.get("test_collection", data)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–æ–ª–µ "tests" (—Å—Ç–∞—Ä–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞) –∏–ª–∏ "topics" (–Ω–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
    topics_data = test_collection_data.get("topics") or test_collection_data.get("tests", [])

    topics: list[Topic] = [
        Topic(
            topic_id=test.get("topic_id", test.get("test_id", "")),
            topic_name=test["topic_name"],
            questions=[Question(**q) for q in test["questions"]],
        )
        for test in topics_data
    ]

    test_collection = TestCollection(
        creation_date=test_collection_data["creation_date"],
        total_questions=test_collection_data["total_questions"],
        topics_count=test_collection_data["topics_count"],
        topics=topics,
    )

    verifications = asyncio.run(process_verifications(test_collection))
    metrics = calculate_metrics(verifications)

    report = EffectivenessReport(
        report_date=datetime.now().isoformat(),
        overall_metrics=metrics,
        verifications=verifications,
    )

    output = generate_markdown_report(report)
    Path(args.output).write_text(output, encoding="utf-8")
    print(output)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--test-data", required=True, help="–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
    parser.add_argument("--language", default="ru", help="–Ø–∑—ã–∫ –¥–ª—è –æ—Ç—á–µ—Ç–∞")
    parser.add_argument(
        "--output", default="effectiveness_report.md", help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É"
    )
    main(parser.parse_args())
