{
  "topic_id": "intermediate_04",
  "topic": "Двоичное дерево поиска BST",
  "user_level": "intermediate",
  "success": true,
  "material_length": 6270,
  "word_count": 797,
  "tot_iterations": 18,
  "explored_nodes": 18,
  "final_completeness": 0.6,
  "documents_collected": 5,
  "completeness_score": 0.6,
  "relevance_score": 0.8,
  "quality_score": 0.7,
  "generation_time_seconds": 195.13350558280945,
  "gigachat2_calls": 8,
  "gigachat3_calls": 32,
  "estimated_cost_usd": 0.032,
  "tools_used": [
    "extract_concepts",
    "web_search",
    "adaptive_rag_search"
  ],
  "generation_id": "gen_0fac02e0e3b5",
  "warnings": [],
  "fallbacks_used": [],
  "error": null,
  "generated_material": "# Учебный материал по теме «Двоичное дерево поиска»\n\n## Введение\n\nДвоичное дерево поиска (BST, Binary Search Tree) — это специальная структура данных, предназначенная для эффективного хранения и обработки упорядоченных наборов данных. Она позволяет быстро находить, вставлять и удалять элементы, обеспечивая среднее время выполнения операций порядка O(log n). \n\nЭта структура широко используется во многих приложениях, включая базы данных, файловые системы, компиляторы и другие программы, где важна быстрая обработка больших объемов данных. Например, в базах данных деревья используются для индексации таблиц, ускоряя выборку нужных строк.\n\n## Основная теория\n\n### Определение\n\nДвоичное дерево поиска — это такое двоичное дерево, в котором выполняется следующее свойство:\n\n- Все элементы левого поддерева узла строго меньше значения узла.\n- Все элементы правого поддерева узла строго больше значения узла.\n\nЭто свойство обеспечивает возможность быстрого поиска нужного элемента путем последовательного сужения области поиска.\n\n### Представление в памяти\n\nКаждый узел дерева содержит:\n\n```python\nclass Node:\n    def __init__(self, key):\n        self.key = key       # ключ узла\n        self.left = None     # указатель на левого сына\n        self.right = None    # указатель на правого сына\n```\n\nИногда полезно хранить ссылку на родителя (`parent`), хотя она необязательна.\n\n### Основные операции\n\n#### 1. Поиск элемента\n\nАлгоритм поиска работает следующим образом:\n\n- Начинаем с корня.\n- Если текущее значение совпадает с искомым, останавливаемся.\n- Иначе, если искомое значение меньше текущего, продолжаем поиск в левом поддереве.\n- Если больше — в правом.\n\nВремя работы: $O(\\log n)$ в среднем, $O(n)$ в худшем случае (вырожденное дерево).\n\nКод поиска:\n\n```python\ndef search(root, target):\n    if root is None or root.key == target:\n        return root\n    elif target < root.key:\n        return search(root.left, target)\n    else:\n        return search(root.right, target)\n```\n\n#### 2. Минимум и максимум\n\n- Чтобы найти минимум, спускаемся по левым ветвям до упора.\n- Чтобы найти максимум, спускаемся по правым ветвям до упора.\n\nВремя работы: $O(\\log n)$.\n\n```python\ndef find_minimum(root):\n    while root.left is not None:\n        root = root.left\n    return root\n\ndef find_maximum(root):\n    while root.right is not None:\n        root = root.right\n    return root\n```\n\n#### 3. Следующий и предыдущий элемент\n\nСледующим элементом после узла `x` считается минимальное значение среди тех, кто больше `x`. И наоборот, предыдущим — максимальное значение среди тех, кто меньше `x`.\n\nВремя работы: $O(\\log n)$.\n\n```python\ndef successor(node):\n    if node.right is not None:\n        return find_minimum(node.right)\n    \n    parent = node.parent\n    while parent is not None and node == parent.right:\n        node = parent\n        parent = parent.parent\n    return parent\n```\n\n#### 4. Вставка нового элемента\n\nПроцесс похож на поиск: спускаемся вниз по дереву, выбирая направление в зависимости от значения ключа. После достижения листа добавляем новый узел.\n\nВремя работы: $O(\\log n)$.\n\n```python\ndef insert(root, new_key):\n    if root is None:\n        return Node(new_key)\n    \n    if new_key < root.key:\n        root.left = insert(root.left, new_key)\n        root.left.parent = root\n    else:\n        root.right = insert(root.right, new_key)\n        root.right.parent = root\n        \n    return root\n```\n\n#### 5. Удаление элемента\n\nУдаление сложнее остальных операций, так как нужно поддерживать балансировку дерева. Возможны несколько случаев:\n\n- Лист удаляется простым сбросом ссылок.\n- У узла один ребенок — заменяем ссылкой на ребенка.\n- У узла два ребенка — заменяем его ближайшим преемником (например, минимальными значениями из правого поддерева).\n\nВремя работы: $O(\\log n)$.\n\n```python\ndef delete_node(root, key):\n    if root is None:\n        return root\n    \n    if key < root.key:\n        root.left = delete_node(root.left, key)\n    elif key > root.key:\n        root.right = delete_node(root.right, key)\n    else:\n        if root.left is None:\n            temp = root.right\n            root = None\n            return temp\n        elif root.right is None:\n            temp = root.left\n            root = None\n            return temp\n            \n        temp = find_minimum(root.right)\n        root.key = temp.key\n        root.right = delete_node(root.right, temp.key)\n    \n    return root\n```\n\n### Время и пространство\n\n| Операция      | Среднее время | Худшее время |\n|---------------|---------------|--------------|\n| Поиск         | O(log n)      | O(n)         |\n| Вставка       | O(log n)      | O(n)         |\n| Удаление      | O(log n)      | O(n)         |\n| Найти min/max | O(log n)      | O(n)         |\n\nПространство: O(n).\n\n## Практика\n\nРассмотрим пример простого дерева поиска:\n\n```\n      5\n     / \\\n    3   8\n   / \\   \n  2   4  \n```\n\nДопустим, нам нужно найти элемент 4. Мы начинаем с корня (5), затем двигаемся влево (3), далее вправо (4) и находим нужный элемент.\n\nТеперь попробуем удалить элемент 3. Так как у него есть оба ребёнка, мы найдем ближайшего наследника (4), перенесем его на место удалённого узла и обновим связи.\n\n## Сравнение с аналогами\n\n- **Связанный список**: медленнее (O(n)) для большинства операций.\n- **Отсортированные массивы**: быстрее для поиска (O(log n)), но медленные изменения структуры (O(n)).\n- **Самобалансирующиеся деревья**: обеспечивают гарантированное время O(log n), но требуют дополнительной логики для поддержания баланса.\n\n## Практические советы\n\n1. Всегда проверяйте высоту дерева: вырожденные деревья сильно замедляют работу.\n2. Используйте самобалансирующиеся варианты (AVL, красно-чёрные деревья), когда нужна гарантия производительности.\n3. Не забывайте про обработку граничных случаев (листья, пустые деревья).\n4. Храните дополнительную информацию (родителей, размеры поддеревьев) для ускорения некоторых операций.\n\n## Дополнительные материалы\n\n- Википедия: https://ru.wikipedia.org/wiki/%D0%94%D0%B2%D0%BE%D0%B8%D1%87%D0%BD%D0%BE%D0%B5_%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE_%D0%BF%D0%BE%D0%B8%D1%81%D0%BA%D0%B0\n- Книга \"Introduction to Algorithms\" by Thomas H. Cormen et al.\n\nЭтот материал поможет вам освоить основы работы с двоичными деревьями поиска и эффективно применять их в реальных проектах."
}