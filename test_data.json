{
  "creation_date": "2025-12-15",
  "total_questions": 75,
  "topics_count": 5,
  "topics": [
    {
      "topic_id": "topic_1",
      "topic_name": "Сложность алгоритмов и Big O",
      "questions": [
        {
          "question_id": 1,
          "difficulty": "easy",
          "question_text": "Какова временная сложность бинарного поиска в отсортированном массиве из n элементов?",
          "expected_answer": "Временная сложность бинарного поиска составляет O(log n), где n — количество элементов в массиве. На каждом шаге алгоритм делит пространство поиска пополам, что приводит к логарифмической сложности. При каждой итерации размер области поиска уменьшается вдвое, поэтому для массива из 1000 элементов потребуется около 10 сравнений.",
          "user_answer": "O(log n), потому что на каждом шаге массив делится пополам и область поиска уменьшается.",
          "key_points": [
            "O(log n)",
            "Деление пространства поиска пополам",
            "Логарифмическая зависимость от размера",
            "Уменьшение области поиска в 2 раза на каждом шаге"
          ],
          "is_correct": true
        },
        {
          "question_id": 2,
          "difficulty": "easy",
          "question_text": "Что означает нотация O(1) для алгоритма?",
          "expected_answer": "Нотация O(1) означает константную временную сложность. Это значит, что время выполнения алгоритма не зависит от размера входных данных и остается постоянным. Примеры операций с O(1): доступ к элементу массива по индексу, вставка в начало связного списка при наличии указателя на голову.",
          "user_answer": "Это когда алгоритм выполняется очень быстро за одну операцию.",
          "key_points": [
            "Константная временная сложность",
            "Не зависит от размера входных данных",
            "Время выполнения постоянно",
            "Примеры: доступ по индексу, операции со стеком"
          ],
          "is_correct": false
        },
        {
          "question_id": 3,
          "difficulty": "easy",
          "question_text": "Какова временная сложность линейного поиска элемента в неотсортированном массиве?",
          "expected_answer": "Временная сложность линейного поиска составляет O(n), где n — количество элементов в массиве. В худшем случае алгоритм должен проверить каждый элемент массива, чтобы найти искомое значение или убедиться в его отсутствии. В среднем случае сложность также остается O(n).",
          "user_answer": "O(n), так как нужно проверить все элементы массива в худшем случае.",
          "key_points": [
            "O(n)",
            "Проверка каждого элемента",
            "Худший случай — элемент в конце или отсутствует",
            "Линейная зависимость от размера"
          ],
          "is_correct": true
        },
        {
          "question_id": 4,
          "difficulty": "medium",
          "question_text": "Какова временная сложность алгоритма быстрой сортировки (quicksort) в среднем и худшем случае?",
          "expected_answer": "Временная сложность быстрой сортировки в среднем случае составляет O(n log n), где алгоритм эффективно разделяет массив на подзадачи. В худшем случае, когда каждый раз выбирается наихудший опорный элемент (например, в уже отсортированном массиве), сложность составляет O(n²). Худший случай можно избежать, используя рандомизированный выбор опорного элемента.",
          "user_answer": "В среднем O(n log n), в худшем O(n²). Худший случай возникает при плохом выборе pivot элемента.",
          "key_points": [
            "Средний случай: O(n log n)",
            "Худший случай: O(n²)",
            "Худший случай при неудачном выборе опорного элемента",
            "Возможна рандомизация для улучшения"
          ],
          "is_correct": true
        },
        {
          "question_id": 5,
          "difficulty": "medium",
          "question_text": "Что означает квадратичная временная сложность O(n²) и приведите пример алгоритма с такой сложностью?",
          "expected_answer": "Квадратичная временная сложность O(n²) означает, что время выполнения алгоритма растет пропорционально квадрату размера входных данных. Если размер входных данных удваивается, время выполнения увеличивается в 4 раза. Примеры алгоритмов: пузырьковая сортировка, сортировка вставками, сортировка выбором, наивный алгоритм проверки всех пар элементов.",
          "user_answer": "Это когда есть вложенные циклы, которые оба проходят по массиву. Например, bubble sort.",
          "key_points": [
            "Время растет пропорционально квадрату размера",
            "Удвоение данных = учетверение времени",
            "Примеры: пузырьковая, сортировка вставками/выбором",
            "Часто связано с вложенными циклами"
          ],
          "is_correct": true
        },
        {
          "question_id": 6,
          "difficulty": "medium",
          "question_text": "Какова временная сложность сортировки слиянием (merge sort)?",
          "expected_answer": "Временная сложность сортировки слиянием составляет O(n log n) как в среднем, так и в худшем случае. Алгоритм рекурсивно делит массив пополам (log n уровней) и затем сливает отсортированные части (n операций на каждом уровне). Это делает merge sort стабильным алгоритмом с предсказуемой производительностью.",
          "user_answer": "O(n log n) во всех случаях, потому что алгоритм всегда делит массив пополам.",
          "key_points": [
            "O(n log n) в любом случае",
            "Рекурсивное деление пополам (log n уровней)",
            "Слияние на каждом уровне (n операций)",
            "Стабильная сложность"
          ],
          "is_correct": true
        },
        {
          "question_id": 7,
          "difficulty": "medium",
          "question_text": "Что такое пространственная сложность алгоритма и чем она отличается от временной?",
          "expected_answer": "Пространственная сложность алгоритма измеряет объем дополнительной памяти, которую использует алгоритм в зависимости от размера входных данных. В отличие от временной сложности, которая оценивает количество операций, пространственная сложность оценивает потребление памяти. Учитываются переменные, структуры данных, стек вызовов рекурсивных функций.",
          "user_answer": "Это сколько памяти нужно алгоритму, а временная — сколько времени. Например, рекурсивные функции используют много памяти для стека.",
          "key_points": [
            "Измеряет объем дополнительной памяти",
            "Отличие от временной: память vs операции",
            "Учитывает переменные, структуры, стек вызовов",
            "Зависит от размера входных данных"
          ],
          "is_correct": true
        },
        {
          "question_id": 8,
          "difficulty": "medium",
          "question_text": "Какова временная сложность операции вставки элемента в середину обычного массива?",
          "expected_answer": "Временная сложность вставки элемента в середину массива составляет O(n), где n — количество элементов. Это связано с необходимостью сдвинуть все элементы после места вставки на одну позицию вправо. В среднем придется сдвинуть n/2 элементов, что дает линейную сложность O(n).",
          "user_answer": "O(1), потому что мы просто вставляем элемент в нужную позицию.",
          "key_points": [
            "O(n)",
            "Необходимость сдвига элементов вправо",
            "В среднем сдвиг n/2 элементов",
            "Линейная зависимость от размера"
          ],
          "is_correct": false
        },
        {
          "question_id": 9,
          "difficulty": "hard",
          "question_text": "Объясните, почему амортизированная сложность операции добавления элемента в динамический массив (например, ArrayList в Java) составляет O(1), хотя иногда требуется перевыделение памяти?",
          "expected_answer": "Амортизированная сложность добавления элемента O(1) достигается за счет стратегии удвоения размера массива. Когда массив заполняется, его размер увеличивается в 2 раза, и все элементы копируются в новый массив. Эта операция имеет сложность O(n), но происходит редко. Если анализировать последовательность из n операций вставки, суммарная стоимость составит O(n), что дает амортизированную стоимость O(1) на одну операцию.",
          "user_answer": "Потому что перераспределение памяти происходит редко, обычно мы просто добавляем элемент за O(1).",
          "key_points": [
            "Стратегия удвоения размера массива",
            "Редкие дорогие операции O(n)",
            "Анализ последовательности n операций",
            "Суммарная стоимость O(n) для n операций",
            "Амортизированная стоимость O(1) на операцию"
          ],
          "is_correct": false
        },
        {
          "question_id": 10,
          "difficulty": "hard",
          "question_text": "Какова временная сложность алгоритма Дейкстры для поиска кратчайшего пути в графе с использованием приоритетной очереди на основе бинарной кучи?",
          "expected_answer": "Временная сложность алгоритма Дейкстры с приоритетной очередью на бинарной куче составляет O((V + E) log V), где V — количество вершин, E — количество ребер. Каждая вершина извлекается из очереди один раз (V операций по log V), и для каждого ребра выполняется операция уменьшения ключа (E операций по log V). Это значительно эффективнее наивной реализации с O(V²).",
          "user_answer": "O((V + E) log V), где V это вершины, E это ребра. Используется бинарная куча для приоритетной очереди.",
          "key_points": [
            "O((V + E) log V)",
            "V операций извлечения из кучи по log V",
            "E операций уменьшения ключа по log V",
            "Использование бинарной кучи",
            "Эффективнее наивной реализации O(V²)"
          ],
          "is_correct": true
        }
      ]
    },
    {
      "topic_id": "topic_2",
      "topic_name": "Деревья и сбалансированные структуры данных",
      "questions": [
        {
          "question_id": 11,
          "difficulty": "easy",
          "question_text": "Что такое бинарное дерево поиска (BST) и какое основное свойство оно должно поддерживать?",
          "expected_answer": "Бинарное дерево поиска (BST) — это дерево, в котором каждый узел имеет не более двух потомков. Основное свойство: для каждого узла все значения в левом поддереве меньше значения узла, а все значения в правом поддереве больше значения узла. Это свойство позволяет эффективно выполнять операции поиска, вставки и удаления.",
          "user_answer": "BST это дерево где у каждого узла максимум два ребенка, и левый меньше родителя, а правый больше.",
          "key_points": [
            "Каждый узел имеет не более двух потомков",
            "Левое поддерево < узел",
            "Правое поддерево > узел",
            "Свойство для всех узлов дерева"
          ],
          "is_correct": true
        },
        {
          "question_id": 12,
          "difficulty": "easy",
          "question_text": "Какова временная сложность поиска элемента в сбалансированном бинарном дереве поиска?",
          "expected_answer": "Временная сложность поиска в сбалансированном бинарном дереве поиска составляет O(log n), где n — количество узлов в дереве. Сбалансированность гарантирует, что высота дерева пропорциональна log n, поэтому путь от корня до любого листа проходит через O(log n) узлов.",
          "user_answer": "O(log n) потому что дерево сбалансировано и высота небольшая.",
          "key_points": [
            "O(log n)",
            "Высота пропорциональна log n",
            "Сбалансированность гарантирует эффективность",
            "Путь от корня до листа логарифмический"
          ],
          "is_correct": true
        },
        {
          "question_id": 13,
          "difficulty": "easy",
          "question_text": "Какова временная сложность поиска в несбалансированном (вырожденном) бинарном дереве поиска?",
          "expected_answer": "В несбалансированном или вырожденном бинарном дереве поиска (когда дерево превращается в связный список) временная сложность поиска составляет O(n), где n — количество узлов. Это происходит, когда элементы добавлялись в отсортированном порядке, и каждый узел имеет только одного потомка.",
          "user_answer": "O(log n), как в обычном дереве поиска.",
          "key_points": [
            "O(n) в худшем случае",
            "Дерево вырождается в список",
            "Происходит при вставке в отсортированном порядке",
            "Каждый узел имеет только одного потомка"
          ],
          "is_correct": false
        },
        {
          "question_id": 14,
          "difficulty": "medium",
          "question_text": "Что такое AVL-дерево и какое основное свойство балансировки оно поддерживает?",
          "expected_answer": "AVL-дерево — это самобалансирующееся бинарное дерево поиска, названное по именам изобретателей Адельсона-Вельского и Ландиса. Основное свойство: для каждого узла разница высот его левого и правого поддерева (фактор баланса) не превышает 1. При нарушении этого свойства выполняются повороты для восстановления баланса. Это гарантирует логарифмическую высоту дерева и O(log n) для всех операций.",
          "user_answer": "AVL-дерево это сбалансированное дерево, где левое и правое поддерево каждого узла отличаются по высоте максимум на 1.",
          "key_points": [
            "Самобалансирующееся BST",
            "Разница высот поддеревьев ≤ 1",
            "Фактор баланса проверяется для каждого узла",
            "Повороты для восстановления баланса",
            "Гарантирует O(log n) операции"
          ],
          "is_correct": true
        },
        {
          "question_id": 15,
          "difficulty": "medium",
          "question_text": "Какие типы поворотов используются для балансировки AVL-дерева?",
          "expected_answer": "Для балансировки AVL-дерева используются четыре типа поворотов: одинарный правый поворот (right rotation) для случая left-left, одинарный левый поворот (left rotation) для случая right-right, лево-правый поворот (left-right rotation) для случая left-right и право-левый поворот (right-left rotation) для случая right-left. Выбор поворота зависит от того, в каком поддереве произошло нарушение баланса.",
          "user_answer": "Используются правый и левый повороты, а также двойные повороты для сложных случаев.",
          "key_points": [
            "Четыре типа поворотов",
            "Одинарный правый (left-left)",
            "Одинарный левый (right-right)",
            "Лево-правый и право-левый двойные повороты",
            "Выбор зависит от места нарушения"
          ],
          "is_correct": false
        },
        {
          "question_id": 16,
          "difficulty": "medium",
          "question_text": "Что такое красно-черное дерево и какие основные свойства оно поддерживает?",
          "expected_answer": "Красно-черное дерево — это самобалансирующееся бинарное дерево поиска, где каждый узел имеет цвет (красный или черный). Основные свойства: корень всегда черный, красный узел не может иметь красного родителя, все пути от узла до листьев содержат одинаковое количество черных узлов, листья (NIL) черные. Эти свойства гарантируют, что самый длинный путь не более чем в 2 раза длиннее самого короткого.",
          "user_answer": "Красно-черное дерево это дерево где узлы красные или черные. Корень черный, и два красных узла не могут быть рядом.",
          "key_points": [
            "Самобалансирующееся BST с цветами узлов",
            "Корень черный",
            "Красный узел не имеет красного родителя",
            "Одинаковое количество черных узлов на всех путях",
            "Самый длинный путь ≤ 2× самого короткого"
          ],
          "is_correct": true
        },
        {
          "question_id": 17,
          "difficulty": "medium",
          "question_text": "Опишите три основных способа обхода бинарного дерева.",
          "expected_answer": "Три основных способа обхода: 1) Прямой обход (pre-order) — сначала текущий узел, затем левое поддерево, затем правое. 2) Центрированный обход (in-order) — сначала левое поддерево, затем текущий узел, затем правое; для BST дает отсортированную последовательность. 3) Обратный обход (post-order) — сначала левое поддерево, затем правое, затем текущий узел. Все обходы можно реализовать рекурсивно или итеративно с использованием стека.",
          "user_answer": "Pre-order, in-order и post-order. In-order обходит дерево слева направо и дает отсортированный порядок для BST.",
          "key_points": [
            "Pre-order: узел, левое, правое",
            "In-order: левое, узел, правое (дает сортировку для BST)",
            "Post-order: левое, правое, узел",
            "Можно реализовать рекурсивно или итеративно"
          ],
          "is_correct": true
        },
        {
          "question_id": 18,
          "difficulty": "hard",
          "question_text": "В чем основное отличие между AVL-деревом и красно-черным деревом с точки зрения баланса и производительности операций?",
          "expected_answer": "AVL-деревья более строго сбалансированы (разница высот ≤ 1), что обеспечивает более быстрый поиск, но требует больше поворотов при вставке и удалении. Красно-черные деревья имеют более мягкую балансировку (самый длинный путь ≤ 2× самого короткого), что приводит к более быстрым операциям вставки и удаления, но немного медленнее поиску. В итоге AVL лучше для операций чтения, а красно-черные для операций записи.",
          "user_answer": "AVL деревья более сбалансированы и быстрее ищут, но медленнее вставляют. Красно-черные деревья наоборот — быстрее вставка и удаление.",
          "key_points": [
            "AVL более строгая балансировка (высота ≤ 1)",
            "AVL быстрее поиск, медленнее вставка/удаление",
            "Красно-черные мягче сбалансированы (путь ≤ 2×)",
            "Красно-черные быстрее вставка/удаление, медленнее поиск",
            "Выбор зависит от соотношения операций чтения/записи"
          ],
          "is_correct": true
        },
        {
          "question_id": 19,
          "difficulty": "hard",
          "question_text": "Что такое B-дерево и для каких задач оно оптимально?",
          "expected_answer": "B-дерево — это самобалансирующееся дерево поиска, в котором узлы могут иметь более двух потомков (от t до 2t, где t — минимальная степень). Все листья находятся на одном уровне. B-деревья оптимальны для систем с медленным доступом к памяти, таких как базы данных и файловые системы, так как минимизируют количество обращений к диску за счет хранения множества ключей в одном узле.",
          "user_answer": "B-дерево это дерево где узел может иметь много детей, не только два. Используется в базах данных для индексов.",
          "key_points": [
            "Узлы могут иметь более двух потомков",
            "От t до 2t потомков",
            "Все листья на одном уровне",
            "Оптимально для систем с медленным доступом",
            "Использование в БД и файловых системах",
            "Минимизация обращений к диску"
          ],
          "is_correct": false
        },
        {
          "question_id": 20,
          "difficulty": "hard",
          "question_text": "Объясните, как работает операция удаления узла с двумя потомками в бинарном дереве поиска.",
          "expected_answer": "При удалении узла с двумя потомками нужно найти узел-замену, который сохранит свойство BST. Обычно используется один из двух подходов: 1) находим минимальный элемент в правом поддереве (in-order successor) или 2) находим максимальный элемент в левом поддереве (in-order predecessor). Затем копируем значение найденного узла в удаляемый узел и рекурсивно удаляем узел-замену, который гарантированно имеет не более одного потомка.",
          "user_answer": "Нужно найти минимум в правом поддереве, скопировать его значение в удаляемый узел, и удалить минимальный узел.",
          "key_points": [
            "Нужна замена для сохранения свойства BST",
            "Два варианта: минимум справа или максимум слева",
            "Копирование значения замены",
            "Рекурсивное удаление узла-замены",
            "Узел-замена имеет ≤ 1 потомка"
          ],
          "is_correct": true
        }
      ]
    },
    {
      "topic_id": "topic_3",
      "topic_name": "Графы и алгоритмы обхода",
      "questions": [
        {
          "question_id": 21,
          "difficulty": "easy",
          "question_text": "Что такое граф и какие два основных способа представления графа существуют?",
          "expected_answer": "Граф — это структура данных, состоящая из множества вершин (узлов) и множества ребер, соединяющих эти вершины. Два основных способа представления: 1) Матрица смежности — двумерный массив, где элемент [i][j] показывает наличие ребра между вершинами i и j. 2) Список смежности — для каждой вершины хранится список ее соседей. Матрица эффективна для плотных графов, список — для разреженных.",
          "user_answer": "Граф это вершины и ребра. Можно представить через матрицу смежности или список смежности.",
          "key_points": [
            "Множество вершин и ребер",
            "Матрица смежности — двумерный массив",
            "Список смежности — список соседей для каждой вершины",
            "Выбор зависит от плотности графа"
          ],
          "is_correct": true
        },
        {
          "question_id": 22,
          "difficulty": "easy",
          "question_text": "В чем разница между ориентированным и неориентированным графом?",
          "expected_answer": "В ориентированном графе ребра имеют направление — ребро (A, B) означает связь от A к B, но не обязательно наоборот. В неориентированном графе ребра двунаправленны — связь между A и B работает в обе стороны. Примеры: социальные сети (подписки в Twitter — ориентированный, дружба в Facebook — неориентированный), дорожные карты (односторонние улицы — ориентированные).",
          "user_answer": "В ориентированном графе ребра имеют направление, в неориентированном — нет.",
          "key_points": [
            "Ориентированный: ребра с направлением",
            "Неориентированный: ребра двунаправленны",
            "Разное применение в реальных задачах",
            "Примеры из социальных сетей и карт"
          ],
          "is_correct": true
        },
        {
          "question_id": 23,
          "difficulty": "easy",
          "question_text": "Что такое взвешенный граф?",
          "expected_answer": "Взвешенный граф — это граф, в котором каждое ребро имеет связанное с ним числовое значение (вес). Вес может представлять расстояние, стоимость, время или любую другую метрику. Взвешенные графы используются в задачах поиска кратчайшего пути (например, алгоритм Дейкстры), минимального остовного дерева (алгоритмы Прима и Краскала) и других оптимизационных задачах.",
          "user_answer": "Это граф где каждое ребро имеет вес — число, которое может означать расстояние или стоимость.",
          "key_points": [
            "Каждое ребро имеет числовой вес",
            "Вес представляет метрику (расстояние, стоимость, время)",
            "Используется в задачах оптимизации",
            "Примеры: кратчайший путь, минимальное остовное дерево"
          ],
          "is_correct": true
        },
        {
          "question_id": 24,
          "difficulty": "medium",
          "question_text": "Объясните алгоритм поиска в глубину (DFS). Какая структура данных используется для его реализации?",
          "expected_answer": "DFS (Depth-First Search) — алгоритм обхода графа, который исследует граф, двигаясь как можно глубже по каждой ветви перед возвратом. Алгоритм использует стек (явный или неявный через рекурсию). Процесс: посещаем вершину, помечаем как посещенную, рекурсивно посещаем все непосещенные соседние вершины. Временная сложность O(V + E), где V — вершины, E — ребра. DFS используется для поиска компонент связности, топологической сортировки, обнаружения циклов.",
          "user_answer": "DFS идет вглубь графа, используя стек или рекурсию. Посещает вершину и идет к ее соседям.",
          "key_points": [
            "Обход вглубь по каждой ветви",
            "Использует стек (явный или через рекурсию)",
            "Помечает посещенные вершины",
            "Временная сложность O(V + E)",
            "Применение: компоненты связности, топосортировка, циклы"
          ],
          "is_correct": true
        },
        {
          "question_id": 25,
          "difficulty": "medium",
          "question_text": "Объясните алгоритм поиска в ширину (BFS). Какая структура данных используется для его реализации?",
          "expected_answer": "BFS (Breadth-First Search) — алгоритм обхода графа, который исследует вершины слоями, начиная с начальной вершины. Алгоритм использует очередь. Процесс: помещаем начальную вершину в очередь, извлекаем вершину, посещаем всех ее непосещенных соседей и добавляем их в очередь. Временная сложность O(V + E). BFS используется для поиска кратчайшего пути в невзвешенном графе, проверки двудольности графа, поиска компонент связности.",
          "user_answer": "BFS обходит граф по слоям используя очередь. Сначала посещает все соседи, потом их соседей.",
          "key_points": [
            "Обход послойно от начальной вершины",
            "Использует очередь",
            "Посещает всех соседей текущего уровня",
            "Временная сложность O(V + E)",
            "Применение: кратчайший путь, двудольность, компоненты связности"
          ],
          "is_correct": true
        },
        {
          "question_id": 26,
          "difficulty": "medium",
          "question_text": "В чем основное различие между DFS и BFS с точки зрения использования памяти?",
          "expected_answer": "DFS использует меньше памяти для длинных и узких графов, так как стек содержит только вершины на текущем пути от корня до текущей вершины (глубина графа). BFS требует больше памяти для широких графов, так как очередь может содержать все вершины одного уровня. Пространственная сложность DFS — O(h), где h — максимальная глубина, BFS — O(w), где w — максимальная ширина уровня. В полном бинарном дереве BFS может требовать O(n/2) памяти на последнем уровне.",
          "user_answer": "DFS использует стек, который может быть глубоким, а BFS использует очередь, которая может быть широкой.",
          "key_points": [
            "DFS: память зависит от глубины O(h)",
            "BFS: память зависит от ширины O(w)",
            "DFS экономнее для узких графов",
            "BFS требует больше памяти для широких графов",
            "В полном дереве BFS может требовать O(n/2)"
          ],
          "is_correct": false
        },
        {
          "question_id": 27,
          "difficulty": "medium",
          "question_text": "Как работает алгоритм топологической сортировки и для каких графов он применим?",
          "expected_answer": "Топологическая сортировка — это линейное упорядочивание вершин ориентированного ациклического графа (DAG), при котором для каждого ребра (u, v) вершина u идет перед v. Реализуется через DFS: выполняем DFS, после обработки всех соседей вершины добавляем ее в начало результата. Также можно использовать алгоритм Кана с подсчетом входящих степеней. Применяется для планирования задач с зависимостями, разрешения зависимостей компиляции, порядка выполнения курсов.",
          "user_answer": "Топологическая сортировка упорядочивает вершины так, чтобы все ребра шли слева направо. Работает только для DAG.",
          "key_points": [
            "Линейное упорядочивание вершин DAG",
            "Для ребра (u, v): u перед v",
            "Реализация через DFS или алгоритм Кана",
            "Применяется только к ацикличным графам",
            "Использование: планирование задач, зависимости"
          ],
          "is_correct": true
        },
        {
          "question_id": 28,
          "difficulty": "medium",
          "question_text": "Что такое компонента связности в графе и как ее найти?",
          "expected_answer": "Компонента связности — это максимальное подмножество вершин неориентированного графа, в котором любые две вершины достижимы друг из друга. Граф может содержать несколько изолированных компонент. Для поиска всех компонент: выполняем DFS или BFS из каждой непосещенной вершины, каждый запуск находит одну компоненту. Временная сложность O(V + E). В ориентированных графах различают сильно связные компоненты (алгоритмы Косарайю или Тарьяна).",
          "user_answer": "Компонента связности это группа вершин, между которыми есть пути. Находится с помощью DFS или BFS.",
          "key_points": [
            "Максимальное подмножество связных вершин",
            "Любые две вершины достижимы друг из друга",
            "Поиск через DFS/BFS из непосещенных вершин",
            "Временная сложность O(V + E)",
            "В ориентированных графах — сильно связные компоненты"
          ],
          "is_correct": true
        },
        {
          "question_id": 29,
          "difficulty": "hard",
          "question_text": "Опишите алгоритм Дейкстры для поиска кратчайшего пути. Какие ограничения он имеет?",
          "expected_answer": "Алгоритм Дейкстры находит кратчайшие пути от одной вершины до всех остальных во взвешенном графе. Использует жадный подход: поддерживает множество посещенных вершин и расстояния до них, на каждом шаге выбирает непосещенную вершину с минимальным расстоянием, обновляет расстояния до ее соседей. С приоритетной очередью сложность O((V + E) log V). Ограничения: не работает с отрицательными весами ребер, так как жадный выбор может быть неоптимальным. Для графов с отрицательными весами используется алгоритм Беллмана-Форда.",
          "user_answer": "Алгоритм Дейкстры находит кратчайший путь от одной вершины до всех других. Использует приоритетную очередь и не работает с отрицательными весами.",
          "key_points": [
            "Поиск кратчайших путей от одной вершины",
            "Жадный подход с выбором минимального расстояния",
            "Использует приоритетную очередь",
            "Сложность O((V + E) log V)",
            "Не работает с отрицательными весами",
            "Для отрицательных весов — Беллман-Форд"
          ],
          "is_correct": true
        },
        {
          "question_id": 30,
          "difficulty": "hard",
          "question_text": "Что такое алгоритм Флойда-Уоршелла и в чем его преимущество перед алгоритмом Дейкстры?",
          "expected_answer": "Алгоритм Флойда-Уоршелла находит кратчайшие пути между всеми парами вершин во взвешенном графе. Использует динамическое программирование: для каждой пары вершин (i, j) рассматривает все возможные промежуточные вершины k и выбирает минимальное расстояние. Временная сложность O(V³), пространственная O(V²). Преимущества: работает с отрицательными весами (но не с отрицательными циклами), находит пути между всеми парами за один запуск. Недостаток: кубическая сложность, неэффективен для разреженных графов.",
          "user_answer": "Флойд-Уоршелл находит кратчайшие пути между всеми парами вершин. Работает за O(V³) и может обрабатывать отрицательные веса.",
          "key_points": [
            "Кратчайшие пути между всеми парами вершин",
            "Динамическое программирование",
            "Рассматривает промежуточные вершины",
            "Временная сложность O(V³)",
            "Работает с отрицательными весами",
            "Преимущество: все пары за один запуск"
          ],
          "is_correct": true
        },
        {
          "question_id": 31,
          "difficulty": "hard",
          "question_text": "Объясните, что такое минимальное остовное дерево (MST) и назовите два основных алгоритма для его построения.",
          "expected_answer": "Минимальное остовное дерево (MST) — это подграф связного взвешенного неориентированного графа, который соединяет все вершины без циклов с минимальной суммой весов ребер. MST содержит ровно V-1 ребро для V вершин. Два основных алгоритма: 1) Алгоритм Прима — жадный алгоритм, который начинает с одной вершины и добавляет минимальное ребро, соединяющее дерево с новой вершиной. Сложность O(E log V) с приоритетной очередью. 2) Алгоритм Краскала — сортирует все ребра по весу и добавляет их, если они не создают цикл. Использует структуру Union-Find. Сложность O(E log E).",
          "user_answer": "MST это дерево, которое соединяет все вершины с минимальным весом. Алгоритмы Прима и Краскала используются для его построения.",
          "key_points": [
            "Соединяет все вершины без циклов",
            "Минимальная сумма весов ребер",
            "Содержит V-1 ребро",
            "Алгоритм Прима: жадный, начинает с вершины, O(E log V)",
            "Алгоритм Краскала: сортирует ребра, использует Union-Find, O(E log E)"
          ],
          "is_correct": true
        },
        {
          "question_id": 32,
          "difficulty": "medium",
          "question_text": "Как проверить наличие цикла в ориентированном графе?",
          "expected_answer": "Для проверки цикла в ориентированном графе используется DFS с отслеживанием трех состояний вершин: непосещенная, в процессе обработки (в стеке рекурсии), полностью обработанная. Если во время DFS мы встречаем вершину в состоянии 'в процессе обработки', это означает наличие обратного ребра и, следовательно, цикла. Временная сложность O(V + E). Альтернативный метод: попытка топологической сортировки — если граф имеет цикл, топологическая сортировка невозможна.",
          "user_answer": "Используем DFS и отслеживаем посещенные вершины. Если находим вершину, которая уже в стеке, есть цикл.",
          "key_points": [
            "DFS с тремя состояниями вершин",
            "Состояния: непосещенная, в обработке, обработанная",
            "Обратное ребро указывает на цикл",
            "Временная сложность O(V + E)",
            "Альтернатива: невозможность топосортировки"
          ],
          "is_correct": true
        },
        {
          "question_id": 33,
          "difficulty": "medium",
          "question_text": "Что такое двудольный граф и как проверить, является ли граф двудольным?",
          "expected_answer": "Двудольный граф — это граф, вершины которого можно разделить на два непересекающихся множества так, что каждое ребро соединяет вершины из разных множеств. Для проверки используется BFS или DFS с раскраской вершин в два цвета: начинаем с любой вершины, красим ее в цвет 1, все ее соседи — в цвет 2, их соседи — снова в цвет 1 и т.д. Если встречаем соседнюю вершину того же цвета, граф не двудольный. Временная сложность O(V + E).",
          "user_answer": "Двудольный граф можно разделить на два множества вершин, где ребра только между множествами. Проверяется раскраской в два цвета через BFS.",
          "key_points": [
            "Вершины делятся на два непересекающихся множества",
            "Ребра только между множествами",
            "Проверка через BFS/DFS с двухцветной раскраской",
            "Соседние вершины разных цветов",
            "Временная сложность O(V + E)",
            "Конфликт цветов = не двудольный"
          ],
          "is_correct": true
        }
      ]
    },
    {
      "topic_id": "topic_4",
      "topic_name": "Хеш-таблицы и хеширование",
      "questions": [
        {
          "question_id": 34,
          "difficulty": "easy",
          "question_text": "Что такое хеш-таблица и какова ее основная цель?",
          "expected_answer": "Хеш-таблица — это структура данных, которая хранит пары ключ-значение и обеспечивает быстрый доступ к данным. Использует хеш-функцию для преобразования ключа в индекс массива, где хранится значение. Основная цель — обеспечить операции вставки, поиска и удаления за среднее время O(1). Хеш-таблицы используются в словарях, кэшах, наборах, индексах баз данных и многих других приложениях, требующих быстрого доступа к данным.",
          "user_answer": "Хеш-таблица это структура данных для хранения ключ-значение с быстрым доступом за O(1).",
          "key_points": [
            "Хранит пары ключ-значение",
            "Использует хеш-функцию для индексации",
            "Операции за среднее O(1)",
            "Применение: словари, кэши, индексы"
          ],
          "is_correct": true
        },
        {
          "question_id": 35,
          "difficulty": "easy",
          "question_text": "Что такое хеш-функция и какие требования к ней предъявляются?",
          "expected_answer": "Хеш-функция — это функция, которая преобразует ключ произвольного размера в индекс массива фиксированного размера. Требования: 1) Детерминированность — один и тот же ключ всегда дает одно и то же значение. 2) Равномерное распределение — минимизация коллизий, хеши должны равномерно распределяться по массиву. 3) Быстрое вычисление — должна работать за O(1). 4) Лавинный эффект — небольшое изменение ключа должно давать сильно отличающийся хеш.",
          "user_answer": "Хеш-функция преобразует ключ в индекс массива. Должна быть быстрой и давать одинаковый результат для одного ключа.",
          "key_points": [
            "Преобразует ключ в индекс массива",
            "Детерминированность",
            "Равномерное распределение",
            "Быстрое вычисление O(1)",
            "Лавинный эффект"
          ],
          "is_correct": false
        },
        {
          "question_id": 36,
          "difficulty": "easy",
          "question_text": "Что такое коллизия в хеш-таблице?",
          "expected_answer": "Коллизия в хеш-таблице возникает, когда хеш-функция генерирует один и тот же индекс для двух или более различных ключей. Коллизии неизбежны из-за принципа Дирихле — количество возможных ключей обычно больше размера массива. Существуют различные методы разрешения коллизий: метод цепочек (chaining), открытая адресация (linear probing, quadratic probing, double hashing). Хорошая хеш-функция и правильный размер таблицы минимизируют коллизии.",
          "user_answer": "Коллизия это когда два разных ключа получают один индекс в хеш-таблице.",
          "key_points": [
            "Два разных ключа с одинаковым хешем",
            "Неизбежны из-за принципа Дирихле",
            "Методы разрешения: цепочки, открытая адресация",
            "Хорошая хеш-функция минимизирует коллизии"
          ],
          "is_correct": true
        },
        {
          "question_id": 37,
          "difficulty": "medium",
          "question_text": "Объясните метод цепочек (chaining) для разрешения коллизий в хеш-таблице.",
          "expected_answer": "Метод цепочек — это способ разрешения коллизий, при котором каждая ячейка хеш-таблицы содержит указатель на связный список (или другую структуру) элементов с одинаковым хешем. При вставке элемент добавляется в список соответствующей ячейки. При поиске проходим по списку, сравнивая ключи. Средняя временная сложность O(1 + α), где α = n/m (коэффициент загрузки, n — количество элементов, m — размер таблицы). В худшем случае все элементы в одной цепи — O(n). Преимущество: простота реализации и работа при любом коэффициенте загрузки.",
          "user_answer": "В методе цепочек каждая ячейка содержит список элементов. При коллизии элементы добавляются в список.",
          "key_points": [
            "Каждая ячейка содержит связный список",
            "Элементы с одинаковым хешем в одном списке",
            "Средняя сложность O(1 + α)",
            "Худший случай O(n) — все в одной цепи",
            "Работает при любом коэффициенте загрузки"
          ],
          "is_correct": true
        },
        {
          "question_id": 38,
          "difficulty": "medium",
          "question_text": "Что такое открытая адресация и как работает линейное пробирование (linear probing)?",
          "expected_answer": "Открытая адресация — это метод разрешения коллизий, при котором все элементы хранятся непосредственно в массиве хеш-таблицы без дополнительных структур. При коллизии алгоритм ищет следующую свободную ячейку по определенной стратегии. Линейное пробирование: если ячейка h(k) занята, проверяем h(k)+1, h(k)+2 и т.д. до нахождения свободной. При поиске следуем той же последовательности. Проблема: первичная кластеризация — образование длинных последовательных блоков занятых ячеек, что увеличивает время операций. Требует контроля коэффициента загрузки (обычно < 0.7).",
          "user_answer": "В открытой адресации все элементы в массиве. При коллизии ищем следующую свободную ячейку. Линейное пробирование проверяет последовательно h(k), h(k)+1, h(k)+2...",
          "key_points": [
            "Все элементы в массиве без дополнительных структур",
            "Поиск следующей свободной ячейки при коллизии",
            "Линейное пробирование: h(k), h(k)+1, h(k)+2...",
            "Проблема первичной кластеризации",
            "Требует низкого коэффициента загрузки < 0.7"
          ],
          "is_correct": true
        },
        {
          "question_id": 39,
          "difficulty": "medium",
          "question_text": "Что такое коэффициент загрузки (load factor) хеш-таблицы и почему он важен?",
          "expected_answer": "Коэффициент загрузки (load factor) — это отношение количества элементов в хеш-таблице к размеру массива: α = n/m. Он определяет среднюю длину цепочки в методе цепочек или вероятность коллизии в открытой адресации. При высоком коэффициенте загрузки (близком к 1 или выше) производительность деградирует до O(n). Обычно при достижении порога (например, 0.75 для цепочек, 0.5-0.7 для открытой адресации) выполняется рехеширование — создание новой таблицы большего размера и перенос всех элементов.",
          "user_answer": "Коэффициент загрузки это отношение количества элементов к размеру таблицы. При высоком значении нужно увеличивать таблицу.",
          "key_points": [
            "α = n/m (элементы / размер)",
            "Определяет среднюю длину цепочки или вероятность коллизии",
            "Высокий α снижает производительность",
            "Пороги: 0.75 для цепочек, 0.5-0.7 для открытой адресации",
            "Рехеширование при превышении порога"
          ],
          "is_correct": true
        },
        {
          "question_id": 40,
          "difficulty": "medium",
          "question_text": "Что такое рехеширование (rehashing) и когда оно выполняется?",
          "expected_answer": "Рехеширование — это процесс увеличения размера хеш-таблицы и перевычисления хеш-значений для всех существующих элементов с их последующим переносом в новую таблицу. Выполняется когда коэффициент загрузки превышает определенный порог. Обычно новый размер в 2 раза больше старого (часто выбирается простое число). Операция дорогая — O(n), но выполняется редко, поэтому амортизированная стоимость вставки остается O(1). Рехеширование необходимо для поддержания эффективности операций.",
          "user_answer": "Рехеширование это создание новой большей таблицы и перенос всех элементов. Делается когда таблица заполнена.",
          "key_points": [
            "Увеличение размера таблицы",
            "Перевычисление хешей для всех элементов",
            "Выполняется при превышении коэффициента загрузки",
            "Новый размер обычно в 2 раза больше",
            "Операция O(n), но амортизированная стоимость O(1)"
          ],
          "is_correct": true
        },
        {
          "question_id": 41,
          "difficulty": "hard",
          "question_text": "Объясните, что такое двойное хеширование (double hashing) и каковы его преимущества перед линейным пробированием.",
          "expected_answer": "Двойное хеширование — это метод открытой адресации, использующий две хеш-функции. При коллизии для ключа k проверяем позиции h1(k), h1(k) + h2(k), h1(k) + 2*h2(k) и т.д. Функция h2(k) должна быть взаимно простой с размером таблицы и не должна возвращать 0. Преимущества: устраняет первичную и вторичную кластеризацию, так как шаг пробирования зависит от ключа. Обеспечивает более равномерное распределение элементов по таблице. Недостаток: требует вычисления двух хеш-функций. Пример h2(k): 7 - (k mod 7) для таблицы размера, взаимно простого с 7.",
          "user_answer": "Двойное хеширование использует две хеш-функции для поиска свободной ячейки. Это уменьшает кластеризацию.",
          "key_points": [
            "Использует две хеш-функции h1 и h2",
            "Позиции: h1(k) + i*h2(k)",
            "h2(k) взаимно проста с размером, не равна 0",
            "Устраняет первичную и вторичную кластеризацию",
            "Более равномерное распределение",
            "Недостаток: вычисление двух функций"
          ],
          "is_correct": false
        },
        {
          "question_id": 42,
          "difficulty": "hard",
          "question_text": "Что такое совершенная хеш-функция и когда она применима?",
          "expected_answer": "Совершенная хеш-функция — это хеш-функция, которая не создает коллизий для заданного множества ключей. Каждый ключ отображается в уникальную ячейку. Минимальная совершенная хеш-функция также не оставляет пустых ячеек (размер таблицы равен количеству ключей). Применима когда множество ключей статично и известно заранее (например, зарезервированные слова языка программирования, коды ISO стран). Существуют алгоритмы построения совершенных хеш-функций (например, FKS hashing, CHD algorithm). Преимущество: гарантированное время O(1) для всех операций. Недостаток: не подходит для динамических данных.",
          "user_answer": "Совершенная хеш-функция не создает коллизий. Используется для статических данных, где ключи известны заранее.",
          "key_points": [
            "Нет коллизий для заданного множества ключей",
            "Минимальная: размер = количество ключей",
            "Применяется для статичных данных",
            "Примеры: зарезервированные слова, ISO коды",
            "Алгоритмы построения: FKS, CHD",
            "Гарантированное O(1), но не для динамики"
          ],
          "is_correct": true
        },
        {
          "question_id": 43,
          "difficulty": "medium",
          "question_text": "В чем разница между HashMap и TreeMap с точки зрения временной сложности операций?",
          "expected_answer": "HashMap основана на хеш-таблице и обеспечивает среднее время O(1) для вставки, поиска и удаления, но в худшем случае O(n) при множественных коллизиях. Не поддерживает упорядоченность ключей. TreeMap основана на красно-черном дереве и гарантирует O(log n) для всех операций в любом случае. Поддерживает упорядоченность ключей (естественную или через компаратор). Выбор зависит от требований: HashMap быстрее для большинства операций, TreeMap нужна когда важна упорядоченность или предсказуемая производительность.",
          "user_answer": "HashMap работает за O(1) используя хеширование, TreeMap за O(log n) используя дерево. TreeMap поддерживает порядок ключей.",
          "key_points": [
            "HashMap: среднее O(1), худшее O(n)",
            "TreeMap: гарантированное O(log n)",
            "HashMap на хеш-таблице, TreeMap на красно-черном дереве",
            "HashMap не поддерживает упорядоченность",
            "TreeMap поддерживает упорядоченность ключей",
            "Выбор зависит от требований"
          ],
          "is_correct": true
        },
        {
          "question_id": 44,
          "difficulty": "hard",
          "question_text": "Объясните концепцию криптографической хеш-функции и назовите ее основные свойства.",
          "expected_answer": "Криптографическая хеш-функция — это хеш-функция с усиленными свойствами безопасности для криптографических приложений. Основные свойства: 1) Стойкость к коллизиям первого рода (preimage resistance) — сложно найти исходное сообщение по его хешу. 2) Стойкость к коллизиям второго рода (second preimage resistance) — сложно найти другое сообщение с тем же хешем. 3) Стойкость к коллизиям — сложно найти любую пару сообщений с одинаковым хешем. 4) Лавинный эффект — малое изменение входа сильно меняет выход. Примеры: SHA-256, SHA-3, Blake2. Используются в цифровых подписях, blockchain, хранении паролей.",
          "user_answer": "Криптографическая хеш-функция обеспечивает безопасность данных. Сложно найти два сообщения с одинаковым хешем. Примеры: SHA-256.",
          "key_points": [
            "Усиленные свойства безопасности",
            "Стойкость к коллизиям первого рода (preimage)",
            "Стойкость к коллизиям второго рода (second preimage)",
            "Стойкость к коллизиям",
            "Лавинный эффект",
            "Примеры: SHA-256, SHA-3",
            "Применение: подписи, blockchain, пароли"
          ],
          "is_correct": false
        }
      ]
    },
    {
      "topic_id": "topic_5",
      "topic_name": "Динамическое программирование",
      "questions": [
        {
          "question_id": 45,
          "difficulty": "easy",
          "question_text": "Что такое динамическое программирование и в чем его основная идея?",
          "expected_answer": "Динамическое программирование (ДП) — это метод решения задач путем разбиения их на более простые подзадачи и сохранения результатов подзадач для избежания повторных вычислений. Основная идея: принцип оптимальности Беллмана — оптимальное решение задачи содержит оптимальные решения подзадач. ДП применим когда задача имеет оптимальную подструктуру и перекрывающиеся подзадачи. Два подхода: восходящий (tabulation) — заполнение таблицы снизу вверх, нисходящий (memoization) — рекурсия с кешированием.",
          "user_answer": "ДП это когда мы сохраняем результаты подзадач, чтобы не вычислять их повторно. Используется для оптимизации рекурсивных алгоритмов.",
          "key_points": [
            "Разбиение на простые подзадачи",
            "Сохранение результатов подзадач",
            "Принцип оптимальности Беллмана",
            "Оптимальная подструктура и перекрывающиеся подзадачи",
            "Два подхода: tabulation и memoization"
          ],
          "is_correct": true
        },
        {
          "question_id": 46,
          "difficulty": "easy",
          "question_text": "В чем разница между жадным алгоритмом и динамическим программированием?",
          "expected_answer": "Жадный алгоритм на каждом шаге делает локально оптимальный выбор, надеясь найти глобальный оптимум, не пересматривая предыдущие решения. Работает быстрее, но не всегда дает оптимальное решение. Динамическое программирование рассматривает все возможные варианты, сохраняя результаты подзадач, и гарантирует оптимальное решение. ДП медленнее, но надежнее. Пример: для задачи размена монет жадный алгоритм может не дать оптимума для произвольных номиналов, а ДП всегда найдет минимальное количество монет.",
          "user_answer": "Жадный алгоритм делает оптимальный выбор на каждом шаге, а ДП рассматривает все варианты. ДП медленнее, но точнее.",
          "key_points": [
            "Жадный: локально оптимальный выбор",
            "ДП: рассмотрение всех вариантов",
            "Жадный быстрее, но не всегда оптимален",
            "ДП гарантирует оптимальное решение",
            "Пример различия: задача размена монет"
          ],
          "is_correct": true
        },
        {
          "question_id": 47,
          "difficulty": "easy",
          "question_text": "Как вычислить n-е число Фибоначчи используя динамическое программирование?",
          "expected_answer": "Для вычисления n-го числа Фибоначчи с помощью ДП используется массив для хранения уже вычисленных значений. Восходящий подход: создаем массив fib[n+1], устанавливаем fib[0]=0, fib[1]=1, затем в цикле вычисляем fib[i] = fib[i-1] + fib[i-2] для i от 2 до n. Временная сложность O(n), пространственная O(n). Можно оптимизировать пространство до O(1), храня только два последних значения. Это намного эффективнее наивной рекурсии с O(2^n).",
          "user_answer": "Создаем массив, fib[0]=0, fib[1]=1, затем fib[i] = fib[i-1] + fib[i-2] в цикле. Сложность O(n).",
          "key_points": [
            "Массив для хранения вычисленных значений",
            "Базовые случаи: fib[0]=0, fib[1]=1",
            "Формула: fib[i] = fib[i-1] + fib[i-2]",
            "Временная сложность O(n)",
            "Пространственная O(n) или O(1) с оптимизацией",
            "Эффективнее рекурсии O(2^n)"
          ],
          "is_correct": true
        },
        {
          "question_id": 48,
          "difficulty": "medium",
          "question_text": "Опишите классическую задачу о рюкзаке 0-1 и подход динамического программирования для ее решения.",
          "expected_answer": "Задача о рюкзаке 0-1: дано n предметов с весами w[i] и стоимостями v[i], и рюкзак вместимости W. Нужно выбрать подмножество предметов (каждый либо взять, либо не взять) с максимальной суммарной стоимостью так, чтобы суммарный вес не превышал W. Подход ДП: создаем таблицу dp[i][w], где dp[i][w] — максимальная стоимость для первых i предметов и вместимости w. Рекуррентное соотношение: dp[i][w] = max(dp[i-1][w], dp[i-1][w-weight[i]] + value[i]). Временная и пространственная сложность O(nW).",
          "user_answer": "В задаче о рюкзаке нужно выбрать предметы с максимальной стоимостью, не превышая вес. Используем таблицу dp[i][w] и выбираем: брать или не брать каждый предмет.",
          "key_points": [
            "n предметов с весами и стоимостями, вместимость W",
            "Каждый предмет: взять или не взять",
            "Таблица dp[i][w] — макс стоимость для i предметов и веса w",
            "Рекуррентность: max(не брать, взять)",
            "Временная сложность O(nW)",
            "Пространственная O(nW) или O(W) с оптимизацией"
          ],
          "is_correct": true
        },
        {
          "question_id": 49,
          "difficulty": "medium",
          "question_text": "Что такое задача о наибольшей возрастающей подпоследовательности (LIS) и как ее решить динамическим программированием?",
          "expected_answer": "Задача LIS (Longest Increasing Subsequence): найти длину наибольшей строго возрастающей подпоследовательности в массиве. Подход ДП O(n²): для каждого элемента i вычисляем dp[i] — длину наибольшей возрастающей подпоследовательности, заканчивающейся на i. Формула: dp[i] = max(dp[j] + 1) для всех j < i, где arr[j] < arr[i]. Начальные значения dp[i] = 1. Ответ — максимальное значение в dp. Существует более эффективное решение за O(n log n) с использованием бинарного поиска.",
          "user_answer": "LIS это самая длинная возрастающая подпоследовательность. Для каждого элемента вычисляем длину LIS, заканчивающейся на нем, за O(n²).",
          "key_points": [
            "Длина наибольшей возрастающей подпоследовательности",
            "dp[i] — длина LIS, заканчивающейся на i",
            "Формула: dp[i] = max(dp[j] + 1) для j < i и arr[j] < arr[i]",
            "Начальные значения dp[i] = 1",
            "Временная сложность O(n²)",
            "Существует решение O(n log n)"
          ],
          "is_correct": true
        },
        {
          "question_id": 50,
          "difficulty": "medium",
          "question_text": "Объясните задачу о редакционном расстоянии (Edit Distance) и подход ДП для ее решения.",
          "expected_answer": "Редакционное расстояние (расстояние Левенштейна) — минимальное количество операций (вставка, удаление, замена символа) для преобразования одной строки в другую. Подход ДП: создаем таблицу dp[i][j], где dp[i][j] — расстояние между первыми i символами строки A и первыми j символами строки B. Базовые случаи: dp[i][0] = i, dp[0][j] = j. Рекуррентность: если A[i] == B[j], то dp[i][j] = dp[i-1][j-1], иначе dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]). Временная и пространственная сложность O(mn).",
          "user_answer": "Редакционное расстояние это минимум операций для преобразования строк. Используем таблицу dp[i][j] с операциями вставки, удаления, замены.",
          "key_points": [
            "Минимум операций: вставка, удаление, замена",
            "Таблица dp[i][j] для первых i и j символов",
            "Базовые случаи: dp[i][0] = i, dp[0][j] = j",
            "Рекуррентность: если равны, без операции, иначе 1 + min трех вариантов",
            "Временная сложность O(mn)",
            "Пространственная O(mn) или O(n) с оптимизацией"
          ],
          "is_correct": true
        },
        {
          "question_id": 51,
          "difficulty": "hard",
          "question_text": "Что такое задача о наибольшей общей подпоследовательности (LCS) и как ее решить с помощью ДП?",
          "expected_answer": "Задача LCS (Longest Common Subsequence): найти длину наибольшей подпоследовательности, которая присутствует в двух строках (не обязательно непрерывная). Подход ДП: создаем таблицу dp[i][j], где dp[i][j] — длина LCS для первых i символов строки A и первых j символов строки B. Базовые случаи: dp[i][0] = dp[0][j] = 0. Рекуррентность: если A[i-1] == B[j-1], то dp[i][j] = dp[i-1][j-1] + 1, иначе dp[i][j] = max(dp[i-1][j], dp[i][j-1]). Ответ в dp[m][n]. Для восстановления самой подпоследовательности идем от dp[m][n] назад. Сложность O(mn).",
          "user_answer": "LCS это наибольшая общая подпоследовательность двух строк. Используем таблицу dp[i][j], где если символы совпадают, добавляем 1, иначе берем максимум.",
          "key_points": [
            "Наибольшая подпоследовательность в обеих строках",
            "Таблица dp[i][j] для первых i и j символов",
            "Базовые случаи: dp[i][0] = dp[0][j] = 0",
            "Если символы равны: dp[i-1][j-1] + 1",
            "Иначе: max(dp[i-1][j], dp[i][j-1])",
            "Временная сложность O(mn)",
            "Восстановление подпоследовательности обратным ходом"
          ],
          "is_correct": true
        },
        {
          "question_id": 52,
          "difficulty": "hard",
          "question_text": "Опишите задачу о разбиении множества (Partition Problem) и подход ДП для ее решения.",
          "expected_answer": "Задача о разбиении: дано множество положительных целых чисел, можно ли разбить его на два подмножества с равными суммами? Это NP-полная задача, но решаема ДП за псевдополиномиальное время. Подход: если сумма элементов нечетная, разбиение невозможно. Иначе ищем подмножество с суммой sum/2. Используем таблицу dp[i][s], где dp[i][s] = true, если можно получить сумму s из первых i элементов. Рекуррентность: dp[i][s] = dp[i-1][s] OR dp[i-1][s-arr[i]]. Временная сложность O(n*sum), пространственная O(sum) с оптимизацией.",
          "user_answer": "Задача о разбиении проверяет, можно ли разделить множество на два подмножества с равными суммами. Используем ДП для поиска подмножества с суммой sum/2.",
          "key_points": [
            "Разбиение на два подмножества с равными суммами",
            "Если сумма нечетная — невозможно",
            "Поиск подмножества с суммой sum/2",
            "Таблица dp[i][s] — возможность суммы s из i элементов",
            "Рекуррентность: взять или не взять элемент",
            "Временная сложность O(n*sum) — псевдополиномиальная",
            "NP-полная задача"
          ],
          "is_correct": true
        },
        {
          "question_id": 53,
          "difficulty": "medium",
          "question_text": "Что такое задача о размене монет (Coin Change) и как ее решить динамическим программированием?",
          "expected_answer": "Задача о размене монет: дано множество номиналов монет и сумма, найти минимальное количество монет для получения этой суммы. Подход ДП: создаем массив dp[amount+1], где dp[i] — минимальное количество монет для суммы i. Начальные значения: dp[0] = 0, остальные = ∞. Для каждой суммы i и каждой монеты coin (если coin ≤ i): dp[i] = min(dp[i], dp[i-coin] + 1). Ответ в dp[amount]. Временная сложность O(amount * n), где n — количество номиналов. Вариация: подсчет количества способов размена.",
          "user_answer": "Задача о размене монет ищет минимум монет для суммы. Используем массив dp, где dp[i] минимум для суммы i, обновляя через dp[i-coin] + 1.",
          "key_points": [
            "Минимальное количество монет для суммы",
            "Массив dp[i] — минимум монет для суммы i",
            "Базовый case: dp[0] = 0, остальные = ∞",
            "Для каждой суммы перебираем монеты",
            "Рекуррентность: dp[i] = min(dp[i], dp[i-coin] + 1)",
            "Временная сложность O(amount * n)"
          ],
          "is_correct": true
        },
        {
          "question_id": 54,
          "difficulty": "hard",
          "question_text": "Опишите задачу о матричном умножении с минимальными затратами (Matrix Chain Multiplication) и подход ДП.",
          "expected_answer": "Задача: дано n матриц с размерностями p[0]×p[1], p[1]×p[2], ..., p[n-1]×p[n], найти порядок перемножения с минимальным количеством скалярных операций. Порядок влияет на количество операций: (A×B)×C может быть дешевле чем A×(B×C). Подход ДП: таблица dp[i][j] — минимальная стоимость умножения матриц от i до j. Базовый случай: dp[i][i] = 0. Рекуррентность: dp[i][j] = min(dp[i][k] + dp[k+1][j] + p[i-1]*p[k]*p[j]) для всех k от i до j-1. Временная сложность O(n³), пространственная O(n²).",
          "user_answer": "Задача находит оптимальный порядок перемножения матриц. Используем таблицу dp[i][j] для диапазона матриц, перебирая точки разбиения.",
          "key_points": [
            "Оптимальный порядок умножения n матриц",
            "Порядок влияет на количество операций",
            "Таблица dp[i][j] — стоимость для матриц i..j",
            "Базовый случай: dp[i][i] = 0",
            "Перебор точек разбиения k",
            "Временная сложность O(n³)"
          ],
          "is_correct": true
        },
        {
          "question_id": 55,
          "difficulty": "medium",
          "question_text": "Что такое задача о кратчайшем пути во всех парах вершин и почему для нее подходит динамическое программирование?",
          "expected_answer": "Задача о кратчайших путях во всех парах требует найти кратчайшие расстояния между каждой парой вершин в графе. Алгоритм Флойда-Уоршелла — классический пример ДП для этой задачи. ДП подходит, потому что задача имеет оптимальную подструктуру: кратчайший путь через промежуточные вершины состоит из кратчайших подпутей. Перекрывающиеся подзадачи: расстояния между парами вершин используются многократно при вычислении путей через разные промежуточные вершины. Временная сложность O(V³).",
          "user_answer": "Это задача найти кратчайшие пути между всеми парами вершин. Флойд-Уоршелл использует ДП, рассматривая промежуточные вершины.",
          "key_points": [
            "Кратчайшие пути между всеми парами",
            "Алгоритм Флойда-Уоршелла — пример ДП",
            "Оптимальная подструктура путей",
            "Перекрывающиеся подзадачи расстояний",
            "Рассмотрение промежуточных вершин",
            "Временная сложность O(V³)"
          ],
          "is_correct": true
        },
        {
          "question_id": 56,
          "difficulty": "hard",
          "question_text": "В чем разница между подходами tabulation и memoization в динамическом программировании?",
          "expected_answer": "Tabulation (восходящий подход) — итеративный метод, заполняющий таблицу от базовых случаев к искомому решению. Вычисляет все подзадачи последовательно, даже если некоторые не нужны. Использует итерации и массивы. Memoization (нисходящий подход) — рекурсивный метод с кешированием результатов. Вычисляет только необходимые подзадачи. Использует рекурсию и хеш-таблицу/массив для кеша. Tabulation обычно быстрее (нет накладных расходов рекурсии) и требует меньше памяти стека. Memoization интуитивнее (похож на естественную рекурсию) и вычисляет только нужное.",
          "user_answer": "Tabulation это итеративный подход снизу вверх, memoization это рекурсия с кешированием. Tabulation быстрее, memoization проще понять.",
          "key_points": [
            "Tabulation: итеративный, восходящий",
            "Memoization: рекурсивный, нисходящий с кешем",
            "Tabulation вычисляет все подзадачи",
            "Memoization только необходимые",
            "Tabulation быстрее, меньше стек",
            "Memoization интуитивнее"
          ],
          "is_correct": true
        }
      ]
    },
    {
      "topic_id": "topic_6",
      "topic_name": "Линейные структуры данных и куча",
      "questions": [
        {
          "question_id": 57,
          "difficulty": "easy",
          "question_text": "Что такое стек и какие основные операции он поддерживает?",
          "expected_answer": "Стек — это линейная структура данных, работающая по принципу LIFO (Last In, First Out) — последний вошел, первый вышел. Основные операции: push (добавление элемента на вершину) — O(1), pop (удаление элемента с вершины) — O(1), peek/top (просмотр верхнего элемента без удаления) — O(1), isEmpty (проверка пустоты). Стек используется для вызова функций, обхода в глубину, проверки сбалансированности скобок, вычисления постфиксных выражений, отмены операций.",
          "user_answer": "Стек это структура LIFO. Операции: push добавляет, pop удаляет, peek смотрит верхний элемент. Все за O(1).",
          "key_points": [
            "Принцип LIFO",
            "Push — добавление на вершину O(1)",
            "Pop — удаление с вершины O(1)",
            "Peek — просмотр без удаления O(1)",
            "Применение: вызовы функций, DFS, скобки"
          ],
          "is_correct": true
        },
        {
          "question_id": 58,
          "difficulty": "easy",
          "question_text": "Что такое очередь и какие основные операции она поддерживает?",
          "expected_answer": "Очередь — это линейная структура данных, работающая по принципу FIFO (First In, First Out) — первый вошел, первый вышел. Основные операции: enqueue (добавление элемента в конец) — O(1), dequeue (удаление элемента из начала) — O(1), front/peek (просмотр первого элемента) — O(1), isEmpty (проверка пустоты). Очередь используется для BFS, планирования задач, обработки запросов, буферизации данных. Вариации: приоритетная очередь, двусторонняя очередь (deque).",
          "user_answer": "Очередь это FIFO структура. Enqueue добавляет в конец, dequeue удаляет из начала. Используется в BFS.",
          "key_points": [
            "Принцип FIFO",
            "Enqueue — добавление в конец O(1)",
            "Dequeue — удаление из начала O(1)",
            "Front — просмотр первого O(1)",
            "Применение: BFS, планирование, буферы",
            "Вариации: приоритетная, deque"
          ],
          "is_correct": true
        },
        {
          "question_id": 59,
          "difficulty": "easy",
          "question_text": "Что такое связный список и какие основные виды связных списков существуют?",
          "expected_answer": "Связный список — это линейная структура данных, состоящая из узлов, где каждый узел содержит данные и ссылку на следующий узел. Виды: 1) Односвязный список — каждый узел ссылается только на следующий. 2) Двусвязный список — каждый узел имеет ссылки на следующий и предыдущий узлы. 3) Циклический список — последний узел ссылается на первый. Преимущества: динамический размер, эффективная вставка/удаление O(1) при наличии указателя. Недостатки: доступ по индексу O(n), дополнительная память на ссылки.",
          "user_answer": "Связный список состоит из узлов со ссылками. Бывает односвязный, двусвязный и циклический. Вставка O(1), доступ O(n).",
          "key_points": [
            "Узлы с данными и ссылками",
            "Односвязный: ссылка на следующий",
            "Двусвязный: ссылки на следующий и предыдущий",
            "Циклический: последний ссылается на первый",
            "Вставка/удаление O(1) с указателем",
            "Доступ по индексу O(n)"
          ],
          "is_correct": true
        },
        {
          "question_id": 60,
          "difficulty": "medium",
          "question_text": "В чем преимущества и недостатки связного списка по сравнению с массивом?",
          "expected_answer": "Преимущества связного списка: динамический размер без перевыделения памяти, эффективная вставка/удаление в начале O(1), вставка/удаление в середине O(1) при наличии указателя на узел, нет необходимости в непрерывном блоке памяти. Недостатки: доступ по индексу O(n) вместо O(1), дополнительная память на хранение ссылок, плохая локальность кеша (узлы разбросаны по памяти), сложнее в реализации. Массивы лучше для произвольного доступа, связные списки — для частых вставок/удалений.",
          "user_answer": "Связный список лучше для вставки и удаления, не нужно перемещать элементы. Массив лучше для доступа по индексу за O(1).",
          "key_points": [
            "Связный список: динамический размер",
            "Эффективная вставка/удаление O(1)",
            "Не требует непрерывной памяти",
            "Недостатки: доступ O(n), память на ссылки",
            "Плохая локальность кеша",
            "Массив: доступ O(1), связный список: вставка/удаление O(1)"
          ],
          "is_correct": true
        },
        {
          "question_id": 61,
          "difficulty": "medium",
          "question_text": "Что такое двусторонняя очередь (deque) и какие операции она поддерживает?",
          "expected_answer": "Deque (double-ended queue) — структура данных, позволяющая добавлять и удалять элементы с обоих концов. Основные операции: insertFront (добавление в начало) — O(1), insertRear (добавление в конец) — O(1), deleteFront (удаление из начала) — O(1), deleteRear (удаление из конца) — O(1). Deque может работать и как стек, и как очередь. Реализуется через двусвязный список или циклический массив. Применяется в алгоритме поиска минимума в скользящем окне, A* алгоритме, хранении истории операций.",
          "user_answer": "Deque позволяет добавлять и удалять с обоих концов за O(1). Может работать как стек и как очередь.",
          "key_points": [
            "Добавление/удаление с обоих концов",
            "Все операции O(1)",
            "Объединяет функции стека и очереди",
            "Реализация: двусвязный список или циклический массив",
            "Применение: скользящее окно, A*, история операций"
          ],
          "is_correct": true
        },
        {
          "question_id": 62,
          "difficulty": "medium",
          "question_text": "Что такое бинарная куча и какие основные свойства она имеет?",
          "expected_answer": "Бинарная куча — это полное бинарное дерево, которое удовлетворяет свойству кучи: в max-куче значение каждого узла больше или равно значениям его потомков, в min-куче — меньше или равно. Куча обычно реализуется через массив: для узла с индексом i левый потомок находится в 2i+1, правый в 2i+2, родитель в (i-1)/2. Основные операции: insert (вставка) — O(log n), extractMin/extractMax (извлечение корня) — O(log n), peek (просмотр корня) — O(1), heapify (построение кучи) — O(n). Используется в приоритетных очередях, heap sort, алгоритме Дейкстры.",
          "user_answer": "Бинарная куча это полное бинарное дерево со свойством порядка. Родитель больше (или меньше) потомков. Операции insert и extract за O(log n).",
          "key_points": [
            "Полное бинарное дерево",
            "Max-куча: родитель ≥ потомков, min-куча: родитель ≤ потомков",
            "Реализация через массив",
            "Insert и extract — O(log n)",
            "Peek — O(1)",
            "Heapify — O(n)",
            "Применение: приоритетные очереди, heap sort"
          ],
          "is_correct": true
        },
        {
          "question_id": 63,
          "difficulty": "medium",
          "question_text": "Как работает операция heapify и какова ее временная сложность?",
          "expected_answer": "Heapify — это операция построения кучи из неупорядоченного массива или восстановления свойства кучи для поддерева. Существует два варианта: heapify-down (просеивание вниз) и heapify-up (просеивание вверх). Heapify-down: сравниваем узел с потомками, меняем местами с наибольшим (max-куча) или наименьшим (min-куча) потомком, повторяем для поддерева. Для построения кучи из массива: вызываем heapify-down для всех узлов от (n/2-1) до 0. Временная сложность heapify-down для одного узла — O(log n), для построения всей кучи — O(n), что может показаться неочевидным, но доказывается через анализ высот узлов.",
          "user_answer": "Heapify восстанавливает свойство кучи. Просеивание вниз сравнивает узел с детьми и меняет местами. Построение кучи за O(n).",
          "key_points": [
            "Восстановление свойства кучи",
            "Heapify-down: просеивание вниз",
            "Сравнение с потомками и обмен",
            "Рекурсивно для поддерева",
            "Построение кучи: heapify для узлов от n/2-1 до 0",
            "Одна операция O(log n), построение кучи O(n)"
          ],
          "is_correct": true
        },
        {
          "question_id": 64,
          "difficulty": "hard",
          "question_text": "Объясните, как работает пирамидальная сортировка (heap sort) и какова ее сложность.",
          "expected_answer": "Heap sort — алгоритм сортировки, использующий бинарную кучу. Работает в два этапа: 1) Построение max-кучи из массива — O(n). 2) Извлечение максимальных элементов: меняем местами корень (максимум) с последним элементом, уменьшаем размер кучи на 1, восстанавливаем свойство кучи для корня через heapify-down. Повторяем n раз — O(n log n). Итоговая временная сложность O(n log n) в любом случае. Пространственная сложность O(1) — сортировка на месте. Heap sort не стабильна. Преимущество: гарантированная O(n log n) без дополнительной памяти.",
          "user_answer": "Heap sort строит max-кучу, затем извлекает максимумы, помещая в конец. Сложность O(n log n), сортировка на месте.",
          "key_points": [
            "Использует бинарную max-кучу",
            "Этап 1: построение кучи O(n)",
            "Этап 2: n извлечений с heapify O(n log n)",
            "Общая сложность O(n log n)",
            "Пространственная O(1) — на месте",
            "Не стабильна",
            "Гарантированная производительность"
          ],
          "is_correct": true
        },
        {
          "question_id": 65,
          "difficulty": "medium",
          "question_text": "Что такое приоритетная очередь и как она реализуется?",
          "expected_answer": "Приоритетная очередь — это абстрактная структура данных, где каждый элемент имеет приоритет, и элемент с наивысшим приоритетом извлекается первым. Основные операции: insert (вставка с приоритетом), extractMax/extractMin (извлечение элемента с наивысшим приоритетом), peek (просмотр без извлечения). Обычно реализуется через бинарную кучу: min-куча для минимального приоритета, max-куча для максимального. Временная сложность: insert — O(log n), extract — O(log n), peek — O(1). Применяется в алгоритмах Дейкстры, Прима, A*, планировании задач, событийном моделировании.",
          "user_answer": "Приоритетная очередь извлекает элементы по приоритету. Реализуется через бинарную кучу с операциями за O(log n).",
          "key_points": [
            "Элементы с приоритетами",
            "Извлечение элемента с наивысшим приоритетом",
            "Реализация через бинарную кучу",
            "Insert и extract — O(log n)",
            "Peek — O(1)",
            "Применение: Дейкстра, Прим, планирование"
          ],
          "is_correct": true
        },
        {
          "question_id": 66,
          "difficulty": "hard",
          "question_text": "Что такое фибоначчиева куча и в чем ее преимущество перед бинарной кучей?",
          "expected_answer": "Фибоначчиева куча — это структура данных для приоритетной очереди, состоящая из коллекции деревьев с min-heap порядком. Основные операции: insert — O(1), findMin — O(1), union (слияние двух куч) — O(1), decreaseKey — O(1) амортизированное, extractMin — O(log n) амортизированное. Преимущество перед бинарной кучей: более быстрые операции insert, union и decreaseKey, что критично для алгоритмов Дейкстры и Прима с частыми обновлениями ключей. Недостатки: сложная реализация, большая константа в O-нотации, хуже в практике для небольших данных.",
          "user_answer": "Фибоначчиева куча это коллекция деревьев. Быстрее бинарной для insert и decreaseKey — O(1). Используется в Дейкстре.",
          "key_points": [
            "Коллекция деревьев с min-heap порядком",
            "Insert, findMin, union — O(1) амортизированное",
            "DecreaseKey — O(1) амортизированное",
            "ExtractMin — O(log n) амортизированное",
            "Преимущество: быстрые insert и decreaseKey",
            "Применение: оптимизация Дейкстры и Прима",
            "Недостатки: сложная реализация"
          ],
          "is_correct": true
        },
        {
          "question_id": 67,
          "difficulty": "medium",
          "question_text": "Как реализовать очередь с помощью двух стеков?",
          "expected_answer": "Очередь можно реализовать двумя стеками: stack1 (для enqueue) и stack2 (для dequeue). Операция enqueue: просто помещаем элемент в stack1 — O(1). Операция dequeue: если stack2 пустой, перекладываем все элементы из stack1 в stack2 (переворачивая порядок), затем извлекаем из stack2. Если stack2 не пустой, извлекаем из него. Амортизированная сложность dequeue — O(1), так как каждый элемент перекладывается максимум один раз. Это классическая техника для эмуляции FIFO через два LIFO.",
          "user_answer": "Используем два стека: один для добавления, другой для удаления. При удалении перекладываем элементы из первого во второй, чтобы изменить порядок.",
          "key_points": [
            "Два стека: stack1 для enqueue, stack2 для dequeue",
            "Enqueue: push в stack1 — O(1)",
            "Dequeue: если stack2 пуст, переложить из stack1",
            "Извлечение из stack2",
            "Амортизированная сложность O(1)",
            "Эмуляция FIFO через LIFO"
          ],
          "is_correct": true
        },
        {
          "question_id": 68,
          "difficulty": "medium",
          "question_text": "Что такое циклический буфер (кольцевой буфер) и где он применяется?",
          "expected_answer": "Циклический буфер (ring buffer) — это структура данных фиксированного размера, использующая один блок памяти как замкнутый в кольцо. Использует два указателя: head (начало/чтение) и tail (конец/запись). При достижении конца массива указатели переходят в начало (по модулю размера). Операции enqueue и dequeue — O(1). Преимущества: эффективное использование памяти, кэш-дружественность, подходит для producer-consumer паттерна. Применяется в аудио/видео стриминге, буферизации ввода-вывода, сетевых буферах, embedded системах.",
          "user_answer": "Циклический буфер это массив фиксированного размера с указателями head и tail. При заполнении начинается с начала. Используется для потоков данных.",
          "key_points": [
            "Фиксированный размер, замкнутый в кольцо",
            "Указатели head и tail",
            "Переход по модулю размера",
            "Операции O(1)",
            "Эффективное использование памяти",
            "Применение: стриминг, буферы I/O, producer-consumer"
          ],
          "is_correct": true
        },
        {
          "question_id": 69,
          "difficulty": "hard",
          "question_text": "Как обнаружить цикл в односвязном списке и найти начало цикла?",
          "expected_answer": "Для обнаружения цикла используется алгоритм Флойда 'черепаха и заяц': два указателя, медленный (движется на 1 шаг) и быстрый (на 2 шага). Если есть цикл, они встретятся. Временная сложность O(n), пространственная O(1). Для поиска начала цикла: после встречи помещаем один указатель в начало списка, оба двигаются на 1 шаг. Точка встречи — начало цикла. Это работает из-за математического свойства: расстояние от head до начала цикла равно расстоянию от точки встречи до начала цикла (по циклу).",
          "user_answer": "Используем два указателя: медленный и быстрый. Если встретились, есть цикл. Для начала цикла один указатель в начало списка, оба на 1 шаг до встречи.",
          "key_points": [
            "Алгоритм Флойда с двумя указателями",
            "Медленный на 1 шаг, быстрый на 2",
            "Встреча указывает на цикл",
            "Для начала: один в head, движение на 1 шаг",
            "Временная O(n), пространственная O(1)",
            "Математическое свойство расстояний"
          ],
          "is_correct": true
        },
        {
          "question_id": 70,
          "difficulty": "medium",
          "question_text": "Что такое Skip List и каковы его временные сложности?",
          "expected_answer": "Skip List — это вероятностная структура данных, представляющая собой многоуровневый связный список. Нижний уровень содержит все элементы, каждый следующий уровень содержит подмножество предыдущего (обычно с вероятностью 0.5). Верхние уровни служат 'экспресс-линиями' для ускорения поиска. Поиск начинается с верхнего уровня и спускается вниз. Средние временные сложности: search, insert, delete — O(log n). Пространственная сложность O(n). Преимущества: проще в реализации чем сбалансированные деревья, естественно поддерживает параллелизм. Используется в Redis (Sorted Sets), LevelDB.",
          "user_answer": "Skip List это многоуровневый список, где верхние уровни ускоряют поиск. Операции в среднем O(log n). Проще чем деревья.",
          "key_points": [
            "Многоуровневый связный список",
            "Нижний уровень — все элементы",
            "Верхние уровни — подмножества (вероятностно)",
            "Средняя сложность O(log n)",
            "Пространственная O(n)",
            "Проще деревьев, поддерживает параллелизм",
            "Применение: Redis, LevelDB"
          ],
          "is_correct": true
        }
      ]
    },
    {
      "topic_id": "topic_7",
      "topic_name": "Строковые алгоритмы и продвинутые структуры",
      "questions": [
        {
          "question_id": 71,
          "difficulty": "medium",
          "question_text": "Что такое префиксное дерево (Trie) и для чего оно используется?",
          "expected_answer": "Trie (префиксное дерево) — это древовидная структура данных для хранения множества строк, где каждый узел представляет символ. Путь от корня до узла представляет префикс строки. Общие префиксы хранятся один раз. Операции insert, search, startsWith — O(m), где m — длина строки. Пространственная сложность O(ALPHABET_SIZE * N * M), где N — количество ключей, M — средняя длина. Применяется для автодополнения, проверки орфографии, IP-маршрутизации, словарей, T9-набора. Оптимизированные варианты: compressed trie, radix tree.",
          "user_answer": "Trie это дерево для хранения строк. Каждый узел это символ, общие префиксы делятся. Операции за O(m) где m длина строки.",
          "key_points": [
            "Древовидная структура для строк",
            "Узел представляет символ",
            "Общие префиксы хранятся один раз",
            "Insert, search — O(m)",
            "Применение: автодополнение, словари, IP-маршрутизация",
            "Варианты: compressed trie, radix tree"
          ],
          "is_correct": true
        },
        {
          "question_id": 72,
          "difficulty": "hard",
          "question_text": "Объясните алгоритм Кнута-Морриса-Пратта (KMP) для поиска подстроки.",
          "expected_answer": "KMP — алгоритм поиска подстроки в строке за O(n + m), где n — длина текста, m — длина паттерна. Использует префикс-функцию (LPS массив), которая хранит длину наибольшего собственного префикса-суффикса для каждой позиции паттерна. Построение LPS — O(m). При несовпадении символов не начинаем сначала, а используем LPS для определения следующей позиции проверки, избегая повторных сравнений. Преимущество перед наивным алгоритмом O(n*m): не возвращаемся назад по тексту, каждый символ текста обрабатывается один раз. Применяется в текстовых редакторах, поиске ДНК-последовательностей.",
          "user_answer": "KMP ищет подстроку за O(n+m). Использует префикс-функцию, чтобы не начинать поиск сначала при несовпадении. Каждый символ текста проверяется раз.",
          "key_points": [
            "Поиск подстроки за O(n + m)",
            "Использует префикс-функцию (LPS массив)",
            "LPS хранит длину наибольшего префикса-суффикса",
            "Построение LPS — O(m)",
            "При несовпадении не возвращаемся в тексте",
            "Эффективнее наивного O(n*m)",
            "Применение: текстовые редакторы, биоинформатика"
          ],
          "is_correct": true
        },
        {
          "question_id": 73,
          "difficulty": "hard",
          "question_text": "Что такое суффиксное дерево и какие задачи оно решает?",
          "expected_answer": "Суффиксное дерево — это compressed trie всех суффиксов строки. Каждый путь от корня до листа представляет суффикс. Построение за O(n) (алгоритм Укконена). Пространственная сложность O(n). Позволяет решать множество строковых задач за линейное или близкое время: поиск подстроки O(m), поиск повторяющихся подстрок, наибольшая общая подстрока нескольких строк, подсчет вхождений паттерна. Применяется в биоинформатике (анализ ДНК), сжатии данных, поиске плагиата. Суффиксный массив — компактная альтернатива с похожими возможностями.",
          "user_answer": "Суффиксное дерево хранит все суффиксы строки. Строится за O(n). Позволяет искать подстроки за O(m), находить повторения. Используется в биоинформатике.",
          "key_points": [
            "Compressed trie всех суффиксов",
            "Построение O(n) — алгоритм Укконена",
            "Пространство O(n)",
            "Поиск подстроки O(m)",
            "Задачи: повторения, общие подстроки, подсчет вхождений",
            "Применение: биоинформатика, сжатие, плагиат",
            "Альтернатива: суффиксный массив"
          ],
          "is_correct": true
        },
        {
          "question_id": 74,
          "difficulty": "medium",
          "question_text": "Что такое алгоритм Рабина-Карпа и как он использует хеширование для поиска подстроки?",
          "expected_answer": "Алгоритм Рабина-Карпа использует хеширование для поиска подстроки. Вычисляет хеш-значение паттерна и сравнивает с хешами всех подстрок текста той же длины. Использует скользящее окно и rolling hash для эффективного обновления хеша за O(1) при сдвиге окна. Средняя временная сложность O(n + m), худшая O(n*m) при множественных коллизиях. При совпадении хешей проверяет строки посимвольно (для устранения ложных срабатываний). Преимущество: легко расширяется для поиска нескольких паттернов одновременно, подходит для 2D-поиска паттернов. Применяется в обнаружении плагиата.",
          "user_answer": "Рабин-Карп использует хеши для поиска подстроки. Вычисляет хеш паттерна и сравнивает с хешами окон текста. Rolling hash позволяет обновлять хеш за O(1).",
          "key_points": [
            "Использует хеширование для поиска",
            "Хеш паттерна vs хеши окон текста",
            "Rolling hash для обновления за O(1)",
            "Средняя сложность O(n + m)",
            "При совпадении хешей — проверка строк",
            "Расширяется на множественные паттерны",
            "Применение: плагиат, 2D-поиск"
          ],
          "is_correct": true
        },
        {
          "question_id": 75,
          "difficulty": "hard",
          "question_text": "Что такое алгоритм Ахо-Корасик и для решения каких задач он предназначен?",
          "expected_answer": "Алгоритм Ахо-Корасик — это алгоритм для поиска множества паттернов в тексте одновременно за линейное время. Строит автомат на основе Trie с добавлением ссылок отказа (failure links), которые указывают, куда переходить при несовпадении. Построение автомата — O(sum(|patterns|)), поиск — O(n + m + z), где n — длина текста, m — суммарная длина паттернов, z — количество совпадений. Преимущество перед множественным запуском KMP: одновременный поиск всех паттернов за один проход по тексту. Применяется в антивирусах, системах обнаружения вторжений, биоинформатике, цензурировании текста.",
          "user_answer": "Ахо-Корасик ищет множество паттернов одновременно. Строит автомат на основе Trie с ссылками отказа. Поиск за O(n). Используется в антивирусах.",
          "key_points": [
            "Поиск множества паттернов одновременно",
            "Автомат на основе Trie",
            "Ссылки отказа для переходов при несовпадении",
            "Построение O(sum длин паттернов)",
            "Поиск O(n + m + z)",
            "Один проход по тексту для всех паттернов",
            "Применение: антивирусы, IDS, биоинформатика"
          ],
          "is_correct": true
        }
      ]
    }
  ]
}
